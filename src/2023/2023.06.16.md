- [向量数据库](#向量数据库)
- [13. OpenAI: Function Call](#13-openai-function-call)
- [12. OpenAI 新 API](#12-openai-新-api)
- [11. Azure 改进](#11-azure-改进)
- [10. gpt-engineer 用GPT生成代码](#10-gpt-engineer-用gpt生成代码)
- [09. AIGC](#09-aigc)
- [08. GPT-辅助面试](#08-gpt-辅助面试)
- [07. PDF QA](#07-pdf-qa)
- [06. Mendable AI: 代码网站 QA 系统](#06-mendable-ai-代码网站-qa-系统)
- [05. 论文: UI-任务处理](#05-论文-ui-任务处理)
- [04. Langchain使用: 逆向Twitter更好地理解代码](#04-langchain使用-逆向twitter更好地理解代码)
- [03. FastChat: 基于LangChain和Vicuna-13B的QA](#03-fastchat-基于langchain和vicuna-13b的qa)
- [02. WhisperX: 音频识别 \& 翻译](#02-whisperx-音频识别--翻译)
- [01. AI agent: ChatGPT插件](#01-ai-agent-chatgpt插件)

# 向量数据库

+ 向量: 高维空间的一个点
+ 以向量为索引
+ 非结构化数据: 文本，图像，音频，视频

应用: 推荐系统, 聚类, 相似性搜索, 语义搜索

+ [高维数据检索：基于近邻图的近似最近邻搜索算法](https://zhuanlan.zhihu.com/p/415320221)
    - 算法 NSW HNSW FANNG NGT SPTAG  KGraph EFANNA IEH NSG NSSG Vamana HCNNG
+ [向量检索引擎](https://zhuanlan.zhihu.com/p/364923722)
    - `Faiss` 、`milvus`、`Proxima`、`vearch`、`Jina`

Pinecone: 闭源, 基于 倒排索引 和 局部敏感哈希（LSH）

# 13. [OpenAI: Function Call](https://weibo.com/1727858283/N5cAnc3J8)

Function calling 本质上是OpenAI让API直接支持了Agent或者Plugin！

以前你需要通过Prompt里面加一堆描述支持Agent，现在简单多了，只要在API请求的时候，传入一个functions参数。

functions参数实际上就类似于你要指定的Agent。

注意是functions参数一个数组，也就是可以不止一个function，function是一个对象，可以加上：
name：名称
description：描述，这个很重要，因为GPT需要通过描述来决定是不是用这个函数。
parameters：参数数组，有参数的名字和类型，以及说明

然后返回的结果包含了结构化的内容：
function_call：调用的函数名，和你传入的函数名称一致
arguments：JSON格式的参数值，包含了你调用函数需要的参数名称和值。

例如：
"function_call": { "name": "get_current_weather", "arguments": "{ \"location\": \"Boston, MA\"}" }

我认为function最大的价值是解决了GPT返回数据结构化的问题，不再需要你写复杂的prompt，传入function，你可以保证得到一个跟你的function完全匹配的JSON数据，减少了很多出错和重试的成本！

# 12. [OpenAI 新 API](https://weibo.com/1727858283/N5cjr0jBq)

OpenAI 2023.06.13 发布 新API

+ 16k 上下文 3.5 Turbo 模型（今天向所有人提供）
+ 新的 GPT-4 和 3.5 Turbo 模型
+ Chat Completions API 中的 Function Call，功能等价于 Agent
+ V2 嵌入模型 降价 75%
+ GPT4 API 权限将开放给更多的人

重点：

+ `text-embedding-ada-002` 将成本降低 75% 至每 1K Token 0.0001 美元。
+ `gpt-3.5-turbo-16k` 的定价为每 1K 输入Token 0.003 美元，每 1K 输出Token 0.004 美元。
+ `gpt-3.5-turbo’s` 输入Token的成本降低了 25%

# 11. [Azure 改进](http://t.cn/A6pSfGX6)

有开发者分享，从OpenAI API切换到微软Azure提供的OpenAI API之后：

median latency从15秒减少到3秒

95th percentile latency从60秒减少到15秒

平均每秒处理的token数量增加了三倍，从 8 个增加到 24 个。

# 10. [gpt-engineer 用GPT生成代码](https://github.com/AntonOsika/gpt-engineer)

给GPT一个需求，中间它不明白的会问你，最后一次性给你生成所有代码

# 09. AIGC 

![](../../images/20230613131706.png)

![](../../images/20230613131721.png)

![](../../images/20230613131734.png)

![](../../images/20230613131745.png)

# 08. GPT-辅助面试

![](../../images/20230613131502.jpg)

# 07. PDF QA

现在写长pdf内容问答，只要7行Python代码。但还做不到根据问题自动跳转到给定链接去阅读另一篇pdf然后回答，要做到这一点需要agent的支持。

论文很多都是认为你有相关背景，遇到相关的基础概念或relate work会简单提一句，然后附上链接，如果对基础没啥概念的时候，就需要让ai 自动 去另一篇论文递归搞一遍然后联合给出答案。

![](../../images/20230612100129.jpg)

# 06. [Mendable AI: 代码网站 QA 系统](https://www.mendable.ai/)

刚发现一个工具，输入github网址，然后问问题，要他帮你写代码都可以。

好处：学习一个新的代码库，可以从那里出发，不停的问问题，比gpt会有针对性一点。比你从头看文档会快一点，特别是对相关概念陌生时

特点：答案后面带上了相关文档 代码的链接

# 05. [论文: UI-任务处理](https://arxiv.org/abs/2306.00245)

通过基于像素的预训练和树搜索方法，成功创建了能用屏幕截图和通用动作空间与数字世界进行交互的智能体程序，并在GUI指令遵循任务中取得了优秀的性能。

《From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces》

# 04. [Langchain使用: 逆向Twitter更好地理解代码](https://dev.to/mikeyoung44/a-plain-english-guide-to-reverse-engineering-the-twitter-algorithm-with-langchain-activeloop-and-deepinfra-47fh)

推荐一篇关于 LangChain 的保姆级教程，网页链接，以逆向 Twitter 推荐算法的代码库为例，借助 LangChain 让你像一个经验丰富的老手一般，做到能够快速理解、使用甚至修改代码。

过程中将 LangChain 中的几个关键模块，解释的十分清楚，包括向量数据库储存数据，示例中使用的是 Activeloop 云数据库，讲解如何使用 VectorStores 模块；使用 DeepInfra 提供的 Dolly-v2-12b 来讲解如何使用 LLM 模块；还详细讲解了，如何使用 Conversational RetrieverChain 来实现向量数据库的最佳数据匹配、上下文对话处理等。是一篇很不错的入门教程。

# 03. [FastChat: 基于LangChain和Vicuna-13B的QA](https://lmsys.org/blog/2023-06-09-api-server/?continueFlag=d985a3e8b154443756e90085ded168e1)

通过`FastChat`实现兼容OpenAI的本地API服务，用`LangChain`和`Vicuna-13B`模型进行问答和代码理解等任务

《Building a Truly "Open" OpenAI API Server with Open Models Locally | LMSYS Org》

![](../../images/5396ee05ly8heswtf2s26j20rj0fnab4.jpg)

# 02. [WhisperX: 音频识别 & 翻译](https://github.com/m-bain/whisperX)

web版本见 [这里](https://huggingface.co/spaces/Xenova/whisper-web)

这个程序的特点是可以按照单词对齐时间戳，所以基本上生成的字幕都是完整的句子。生成结果除了srt还有json文件，里面有每一行里面单词的时间戳，可以根据需要二次整理字幕。另外它还能识别发言人，准确率还可以。需要NVIDIA的显卡，好在Google Colab可以运行（需要启用GPU）。

好处是，如果你不想从头看几个小时的课程，可以先弄字幕翻译，然后 先看字幕，有不懂的再回头看对应的画面。这样能节省时间，否则几个小时的视频，很多多是你懂的东西，听也难不听也可惜。

[这里](https://github.com/JimLiu/whisper-subtitles/blob/main/whisperx_youtube_subtitle.ipynb)是个demo，根据YouTube Url识别YouTube字幕的Jupyter Notebook

# 01. [AI agent: ChatGPT插件](https://weibo.com/1727858283/N4EPDxJHt) 

类似于AutoGPT的插件版，能外接存储，能配合其他插件使用

![](../../images/20230611084546.png)