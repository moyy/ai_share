- [AI: 2023.10](#ai-202310)
- [1. 工具](#1-工具)
  - [1.01. Luma AI 支持使用高斯喷射（Gaussian Splatting）技术 构建 交互式 3D场景](#101-luma-ai-支持使用高斯喷射gaussian-splatting技术-构建-交互式-3d场景)
  - [1.02. Instaverse 推出了 Hugging Face 的体验，可以将任何 2D 图像转换为一个完整的 3D 世界](#102-instaverse-推出了-hugging-face-的体验可以将任何-2d-图像转换为一个完整的-3d-世界)
  - [1.03. Manga-Image-Translator 漫画图片翻译器](#103-manga-image-translator-漫画图片翻译器)
  - [1.04. pdf2htmlEX: PDF --\> HTML](#104-pdf2htmlex-pdf----html)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.01. PDFTriage：解决上下文过长的问题](#201-pdftriage解决上下文过长的问题)
  - [2.02. 使用GPT-4 Advanced Data Analysis（原Code Interpreter）功能驱动的交互式模拟人生游戏](#202-使用gpt-4-advanced-data-analysis原code-interpreter功能驱动的交互式模拟人生游戏)
  - [2.03. Octogen：为开发者打造的开源代码解释器](#203-octogen为开发者打造的开源代码解释器)
  - [2.04. llmchain: Rust + LLM](#204-llmchain-rust--llm)
  - [2.05. Lace：用 Rust 写的概率交叉分类引擎，带有可选的 Python 接口](#205-lace用-rust-写的概率交叉分类引擎带有可选的-python-接口)
  - [2.06. `Streaming LLM` 超长上下文](#206-streaming-llm-超长上下文)
  - [2.07. `Perplexity` 推出 pplx-api，访问 LLM 如 Mistral 7B、Llama2 13B等](#207-perplexity-推出-pplx-api访问-llm-如-mistral-7bllama2-13b等)
  - [2.08. `RoleLLM`：增强 LLM 角色扮演 能力](#208-rolellm增强-llm-角色扮演-能力)
  - [2.09. SimplyRetrieve: 通过 检索中心生成 Retrieval-Centric Generation，整合 私人数据 到 LLM](#209-simplyretrieve-通过-检索中心生成-retrieval-centric-generation整合-私人数据-到-llm)
  - [2.10. Odin 用GPT4 从用户数据 生成 知识图谱](#210-odin-用gpt4-从用户数据-生成-知识图谱)
  - [2.11. `AgentVerse` AI小镇又更新新的的资料片了](#211-agentverse-ai小镇又更新新的的资料片了)
- [3. 模型](#3-模型)
  - [3.01. LLaMA 2 Long: 与GPT-4持平，上下文长度达3.2万token](#301-llama-2-long-与gpt-4持平上下文长度达32万token)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.01. 思维链推理相关文献列表](#401-思维链推理相关文献列表)
  - [4.02. 提升 ChatGPT 翻译质量的 Prompt](#402-提升-chatgpt-翻译质量的-prompt)
  - [4.03. 让ChatGPT 校对翻译结果，检查有误遗漏呢？](#403-让chatgpt-校对翻译结果检查有误遗漏呢)
  - [4.04. 《复旦NLP实验室和米哈游全面解读AI Agents》](#404-复旦nlp实验室和米哈游全面解读ai-agents)
  - [4.05. 微软报告：《LMMs 多模态大模型的曙光：初探 GPT-4V》](#405-微软报告lmms-多模态大模型的曙光初探-gpt-4v)
  - [4.06. 动画演示：Transformer 如何使 生成式AI 成为可能](#406-动画演示transformer-如何使-生成式ai-成为可能)
  - [4.07. 《周枫：大模型推理加速技术概要》](#407-周枫大模型推理加速技术概要)
  - [4.08. 《周枫：国产大语言模型何时完成商业闭环？》](#408-周枫国产大语言模型何时完成商业闭环)
  - [4.09. 《周枫：当我们谈论大模型时，应该关注哪些新能力？》](#409-周枫当我们谈论大模型时应该关注哪些新能力)
- [5. 资讯 / 观点](#5-资讯--观点)
  - [5.01. Anthropic/Claude 全面开放 API，与 GPT 的定价比较：](#501-anthropicclaude-全面开放-api与-gpt-的定价比较)

# AI: 2023.10

# 1. 工具

## 1.01. [Luma AI 支持使用高斯喷射（Gaussian Splatting）技术 构建 交互式 3D场景](https://huggingface.co/spaces/ilumine-AI/Retro-to-3D)

让3D场景不仅看起来更逼真，而且渲染速度也更快，这在以前是很难同时实现的。使用就可以拍摄视频并将其转换为逼真的的 3D 场景。

主要特点：

+ 支持浏览器和手机：无论在哪里都能高效快速地进行渲染。
+ 随处嵌入：输出的流媒体文件只有8-20MB，可以嵌入到任何地方。
+ 超高质量的离线NeRF渲染和网格导出：只需用手机捕捉视频即可轻松创建。
+ 广泛的商业应用：该技术已在Luma iOS应用、Luma网站以及Luma API中推出，并且完全可用于商业目的。

## 1.02. [Instaverse 推出了 Hugging Face 的体验，可以将任何 2D 图像转换为一个完整的 3D 世界](https://huggingface.co/spaces/ilumine-AI/Retro-to-3D)

## 1.03. [Manga-Image-Translator 漫画图片翻译器](https://github.com/zyddnys/manga-image-translator/blob/main/README_CN.md)

能够自动翻译漫画图像中的文本速度很快。

支持日语，汉语、英文和韩语。
 ​​​
## 1.04. [pdf2htmlEX: PDF --> HTML](https://github.com/pdf2htmlEX/pdf2htmlEX)
 ​​​
PDF转HTML程序，生成的结果和原始PDF几乎一模一样。

其背后是利用的Chrome Headless，让Chrome渲染PDF，再导出成HTML，甚至图片都转成了 base64 字符，所以一个网页就可以包含完整的文本、字体和图片等内容

# 2. 项目 / 框架

## 2.01. [PDFTriage：解决上下文过长的问题](https://arxiv.org/abs/2309.08872) 

PDFTriage通过先了解文档的结构，然后精准地找到与用户问题相关的部分，最后用语言模型生成答案，从而解决了传统模型在处理长篇和复杂结构文档时的不足。

大型语言模型（LLM）在处理长篇、结构复杂的文档时面临以下几个主要问题：

+ 上下文窗口限制：LLM通常有一个固定的上下文窗口大小，这意味着它一次只能处理有限数量的文本“令牌”（tokens）。对于长篇文档，这就需要进行预处理或分割，以便模型能够处理。
+ 文档结构忽略：传统的LLM通常只处理纯文本，忽略了文档的结构信息（如页面、表格、标题等）。这在处理PDFs、网页或演示文稿等结构复杂的文档时会导致问题。
+ 查询不准确：由于缺乏对文档结构的理解，当用户提出与文档结构有关的问题（例如，“表3中哪一年的收益最高？”）时，传统的LLM往往无法准确回答。
+ 信息获取不全面：在处理结构复杂的文档时，仅仅依赖文本内容可能会导致信息获取不全面或不准确。

工作原理：

根据文档的结构信息，准确地回答用户提出的各种问题。例如，用户可以提出“请总结第5-7页的内容”或“表3中哪一年的收益最高”等问题，PDFTriage能够准确地提供答案。

+ 获取元数据：首先，该技术会生成文档的结构化元数据表达，包括文档各个部分（如段落、标题、表格等）的信息。
+ 选择相关内容：当用户提出一个问题时，该技术会根据元数据选择与问题最相关的文档部分（如特定页面、表格等）。比如，如果问题是“第5-7页的内容是什么？”，它会直接定位到这几页的内容。
+ 生成答案：最后，选定的文档部分和用户的问题会被LLM处理，以生成准确的答案。

用户反馈，PDFTriage生成的答案在多页任务（如结构问题和表格推理）中排名更高，而在一般文本任务（如分类和文本问题）中排名较低。然而，在所有问题类别中，PDFTriage都优于页面检索和块检索方法。

## 2.02. [使用GPT-4 Advanced Data Analysis（原Code Interpreter）功能驱动的交互式模拟人生游戏](https://github.com/EmbraceAGI/LifeReloaded)

游戏内容由 GPT4 实时生成，给您包罗万象，丰富多彩的真实人生体验。

## 2.03. [Octogen：为开发者打造的开源代码解释器](https://github.com/dbpunk-labs/octogen)

## 2.04. [llmchain: Rust + LLM](https://github.com/shafishlabs/llmchain-rs)

## 2.05. [Lace：用 Rust 写的概率交叉分类引擎，带有可选的 Python 接口](https://github.com/promised-ai/lace)

## 2.06. [`Streaming LLM` 超长上下文](https://github.com/mit-han-lab/streaming-llm)

StreamingLLM 通过使语言模型能够顺利处理无尽的文本而不会失去上下文信息流；无需调制即可从预训练的 LLM 中解锁高效且高性能的无限长度流，并且在速度、计算开销和长度泛化性等指标方面优于其他技术。

原理是识别和保留模型固有的“注意力池”，锚定其推理的初始标记。与最近令牌的滚动缓存相结合，StreamingLLM 的推理速度提高了 22 倍，而准确性没有任何下降。

与其他方法相比，StreamingLLM 的主要优势包括：

+ 启用无限长度流，无需增加模型容量或微调模型。扩大注意力窗口等方法需要更多的计算来训练更大的模型。
+ 比带有重新计算的滑动窗口等替代方案更有效。 StreamingLLM 为每个令牌解码提供高达 22 倍的加速。
+ 在比训练长度长得多的文本上表现稳定。与超过 400 万个代币上的滑动窗口基线性能相匹配。
+ 简单且多功能。轻松整合到具有相对位置编码的模型中，例如 RoPE 或 ALiBi。
+ 使用接收器令牌进行预训练，仅使用单个令牌即可进一步增强流媒体能力。
+ 将模型预训练长度与实际生成长度分离。允许扩展模型用例。

## 2.07. [`Perplexity` 推出 pplx-api，访问 LLM 如 Mistral 7B、Llama2 13B等](https://blog.perplexity.ai/blog/introducing-pplx-api)

+ 易于使用，开发者可以在几分钟内通过REST API整合先进的开源模型。   
+ 推理速度很快，比其他解决方案的延迟降低了2-3倍。   
+ 基础设施经过验证，可以承载产品级流量。   
+ 采用NVIDIA TensorRT-LLM和AWS A100 GPU等先进软硬件，实现了优化。   
+ 已用于Perplexity的产品中，相比外部API每年节省了62万美元成本。   
+ 兼容OpenAI API，可以轻松集成到现有应用中。   
+ 未来 将支持更多定制和开源模型。   

## 2.08. [`RoleLLM`：增强 LLM 角色扮演 能力](https://github.com/InteractiveNLP-Team/RoleLLM-public)

现有的开源 LLMs 主要是在通用领域进行训练的，缺乏针对角色扮演的特定优化。

研究人员开发了一种名为“RoleLLM”的增强工具来提高LLMs的角色扮演能力。项目涵盖了100个不同的角色，这些角色来自多个领域和背景。

主要功能：

+ 评估角色扮演能力：不仅提供了一种量化的方法来评估大语言模型（LLMs）在角色扮演方面的性能，还能够对比不同模型之间的性能差异。
+ 引出角色扮演能力：通过特定的训练和指令生成方法，能够从模型中引出其潜在的角色扮演能力。这包括模仿不同角色的说话风格、语气、以及特定的知识和信息。
+ 增强角色扮演能力：通过微调和优化，能够显著提升模型在角色扮演方面的性能。这不仅限于模仿已有的角色，还能够通过用户自定义的角色档案来生成全新的角色。

工作原理：

该工具包括 四个 主要阶段：

+ 角色配置文件构建：为多达100个不同角色（包括95个英文角色和5个中文角色）构建详细的角色档案。这些档案包括角色的基本信息、性格特点、历史背景等。
+ 基于上下文的指令生成：这一阶段用于从角色配置文件中提取角色特定的知识和信息。使用GPT生成高质量的问答对，以从角色配置文件中提取特定的知识和信息。
+ 角色提示：使用 GPT 模型进行角色提示，以模仿不同角色的说话风格。
+ 角色条件指令调整：使用生成的问答对和角色提示，对开源模型进行微调，以增强其角色扮演能力。

工作方法与流程：

该研究还创建了一个名为RoleBench的数据集，这是第一个系统性和细粒度的角色扮演基准数据集，包含168,093个样本。

+ 数据集构建：首先，通过“角色档案构建”和“基于上下文的指令生成”，构建一个名为 RoleBench 的大型数据集。这个数据集包含了168,093个角色扮演样本。
+ 模型训练与微调：接下来，使用“使用 GPT 进行角色提示”和“基于角色条件的指令微调”这两种方法对模型进行训练和微调。
+ 性能评估：最后，通过使用基于 Rouge-L 的三种度量标准和 GPT-based 评估器来全面评估模型在模仿说话风格、回答准确性和捕获角色特定知识方面的表现。

## 2.09. [SimplyRetrieve: 通过 检索中心生成 Retrieval-Centric Generation，整合 私人数据 到 LLM](https://github.com/rcgai/simplyretrieve)

+ 帮助用户将私人数据整合到LLM中。
+ 使用检索中心生成方法，无需额外调优。
+ 该工具能提升AI性能的同时，确保数据隐私的保护。

## 2.10. [Odin 用GPT4 从用户数据 生成 知识图谱](https://github.com/memgraph/odin)

既保证了准确性，也提高了生成速度

为数据分析带来了全新的可能性，被业界看好其在数据科学、人工智能及自然语言处理等领域的广泛应用

## 2.11. [`AgentVerse` AI小镇又更新新的的资料片了](https://github.com/OpenBMB/AgentVerse/blob/main/README_zh.md)

新地图包括审问室（囚徒困境）、教室（举手提问）、996基地（软件开发）、运维地狱（数据库运维）、冒险大陆（宝可梦游戏），并且提供定制化的开发接口

清华大学联合北邮、微信团队推出了名为`AgentVerse`的多智能体宇宙，该环境专门针对大语言模型开发，用户可以通过简单配置设定智能体的出生环境和成长环境，模拟各种社会实验。

+ 清华大学联合北邮、微信团队推出的多智能体宇宙模拟器AgentVerse，能够模拟社会实验，如囚徒困境、NLP课堂等。
+ AgentVerse专门针对大语言模型开发，智能体可以运用LLM的能力完成任务。
+ AgentVerse支持自定义环境配置，只需几行简单配置，就能自定义智能体的出生和成长环境。
+ AgentVerse的工作流程模拟了人类合作解决问题的过程，包括专家招募、讨论合作策略、执行和评估等四个阶段。
+ AgentVerse通过五个基础组件实现自定义环境配置，包括描述器、顺序、选择器、更新器和可见性。

# 3. 模型

## 3.01. LLaMA 2 Long: 与GPT-4持平，上下文长度达3.2万token

和竞争对手相比，在指令微调MMLU (5-shot)等测试集上，表现超过ChatGPT。

在人类评估（human evaluation）上甚至优于10万token的Claude 2，这个话题还在Reddit上引发了讨论。

要知道，这些对比版本中，LLaMA 2 Long使用的最大版本也只有70B，远小于其他大模型。

论文介绍，LLaMA 2 Long使用了4000亿token语料加持下，只改了一个超参数，就实现了如上效果。

# 4. 技巧 / 教程

## 4.01. [思维链推理相关文献列表](https://github.com/zchuz/CoT-Reasoning-Survey) 

## 4.02. [提升 ChatGPT 翻译质量的 Prompt](https://weibo.com/1727858283/NlsDSpPaa)

如果让ChatGPT翻译两次，先直译一次，然后再基于第一次结果意译，整体翻译质量会上一个大台阶，而且经过第二次翻译后，“机翻”的痕迹已经不明显了，很难看出来这是机器翻译的结果。

当然你还可以让ChatGPT继续重写润色，但经过我的实验，对于 GPT-4 来说两次翻译已经是性价比很好的方式，既不用增加很多Token和时间成本，同时得到没有什么“机翻”痕迹的结果。

要多次翻译，并且要输出每一次结果，下一次翻译要基于前面的迭代；翻译文章的时候，如果太长需要手动把文章拆成了大小合适的块，逐批次翻译，最好每次只是编辑之前的内容，避免上下文超长。

Prompt 如下：

``` txt
你是一位精通简体中文的专业翻译，曾参与《纽约时报》和《经济学人》中文版的翻译工作，因此对于新闻和时事文章的翻译有深入的理解。我希望你能帮我将以下英文新闻段落翻译成中文，风格与上述杂志的中文版相似。

规则：
- 翻译时要准确传达新闻事实和背景。
- 保留特定的英文术语或名字，并在其前后加上空格，例如："中 UN 文"。
- 分成两次翻译，并且打印每一次结果：
 
1. 根据新闻内容直译，不要遗漏任何信息
2. 根据第一次直译的结果重新意译，遵守原意的前提下让内容更通俗易懂，符合中文表达习惯

本条消息只需要回复OK，接下来的消息我将会给你发送完整内容，收到后请按照上面的规则打印两次翻译结果。
```

## 4.03. 让ChatGPT 校对翻译结果，检查有误遗漏呢？

我们可以将中文反向翻译回英文对比原始英文的方法来帮助校验翻译的结果是不是有明显遗漏或者添加了额外的信息。

参考Prompt：

``` txt
现在你是专业的翻译审查员，需要对于以下英文翻译成中文的结果进行审查，避免添加或遗漏重要信息导致重大的法律风险。

要求你使用以下步骤进行审查：

1. 忽略“原始英文”，将“中文翻译”反向翻译为英文（反向翻译英文），并打印结果，翻译时按照字面意思直译，尽可能保留原意。
2. 对比“原始英文”和“反向翻译英文”，列出有额外添加的内容或者遗漏的内容
3. 根据上面对比的结果，为“中文翻译”打分，指出其中不足之处

原始英文：
<原始英文>

中文翻译：
<中文翻译>

```

## 4.04. [《复旦NLP实验室和米哈游全面解读AI Agents》](https://mp.weixin.qq.com/s/5pfeHzUPt5TQB6oCpXIpmQ) 

## 4.05. [微软报告：《LMMs 多模态大模型的曙光：初探 GPT-4V》](https://weibo.com/ttarticle/p/show?id=2309404952763347108084)

## 4.06. [动画演示：Transformer 如何使 生成式AI 成为可能](https://baoyu.io/pages/ft/generative-ai)

## 4.07. [《周枫：大模型推理加速技术概要》](https://weibo.com/ttarticle/p/show?id=2309404953923537731893)

## 4.08. [《周枫：国产大语言模型何时完成商业闭环？》](https://weibo.com/ttarticle/p/show?id=2309404943738337362456)

## 4.09. [《周枫：当我们谈论大模型时，应该关注哪些新能力？》](https://weibo.com/ttarticle/p/show?id=2309404893763876290743)

# 5. 资讯 / 观点

## 5.01. Anthropic/Claude 全面开放 API，与 GPT 的定价比较：

GPT4-32k context: 

+ $60/million input tokens 
+ $120/million output tokens

Claude2-100k context: 

+ $11.02/million input tokens 
+ $32.68/million output tokens

GPT3.5-Turbo-16k context:

+ $3/million input tokens
+ $4/million output tokens

Claude Instant-100k context: 

+ $1.63/million input tokens 
+ $5.51/million output tokens
