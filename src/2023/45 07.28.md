- [13. 提示工程 RTF-框架（角色 / 任务 / 格式）](#13-提示工程-rtf-框架角色--任务--格式)
- [12. 从头训练 LLama2 的 C库](#12-从头训练-llama2-的-c库)
- [11. 图像生成视频image-to-video AI工具列表](#11-图像生成视频image-to-video-ai工具列表)
- [10. Langroid: 提供多智能体范式的LLM应用库](#10-langroid-提供多智能体范式的llm应用库)
- [09. Chinese Llama 2 7B](#09-chinese-llama-2-7b)
- [08. 基于 LLama2 的 QA 系统](#08-基于-llama2-的-qa-系统)
- [07. 中文版 Llama2 模型及中英文 SFT 数据集](#07-中文版-llama2-模型及中英文-sft-数据集)
- [06. 单样本微调给ChatGLM2注入知识](#06-单样本微调给chatglm2注入知识)
- [05. MLC LLM项目: 个人设备上部署 LLM](#05-mlc-llm项目-个人设备上部署-llm)
- [04. Clippy：编程助手工具](#04-clippy编程助手工具)
- [03. Code Review GPT](#03-code-review-gpt)
- [02. minigpt4.cpp：MiniGPT4的C++版](#02-minigpt4cppminigpt4的c版)
- [01. Memo（AI 驱动的视频、播客转文字、字幕工具 微博正文 ）技术实现](#01-memoai-驱动的视频播客转文字字幕工具-微博正文-技术实现)

# 13. 提示工程 RTF-框架（角色 / 任务 / 格式）

这个RTF框架用来写Prompt是蛮好的：

+ R = 角色，现在你要充当（角色） 
+ T = 任务，执行（任务）
+ F = 格式，以这种（格式）显示

# 12. [从头训练 LLama2 的 C库](http://github.com/karpathy/llama2.c)

通过PyTorch从头开始训练Llama 2 LLM架构模型，然后将权重保存到一个原始二进制文件中，再将其加载到一个 ~仅有500行的简单C文件（run.c）中，该文件推断模型，目前仅支持fp32。

在作者的云Linux开发平台上，一个维度为288的6层6头模型（约15M个参数）推断速度约为每秒100个令牌；在M1 MacBook Air上推断速度也差不多。

作者有些惊喜地发现，采用这种简单方法，可以以高度交互的速度运行相当大的模型（几千万个参数）。

# 11. [图像生成视频image-to-video AI工具列表](https://weibo.com/5648162302/NbaVhk2Ge)

每种工具生成视频的效果可以看附图↓↓

+ 原图
+ Runway Gen2，runwayml.com
+ Genmo V1，alpha.genmo.ai
+ Pika Labs，只用了10秒，pika.art
+ Kaiber，kaiber.ai
+ Fulljourney，渲染比较长时间，fulljourney.ai
+ Neuralframes，www.neuralframes.com
+ Imagine App

# 10. [Langroid: 提供多智能体范式的LLM应用库](https://github.com/langroid/langroid)

Langroid：一个Python框架，用于构建基于LLM的应用。Langroid提供了一种多智能体编程范式，智能体可以通过交换消息来协同解决问题

# 09. [Chinese Llama 2 7B](https://github.com/LinkSoul-AI/Chinese-Llama-2-7b)

开源社区第一个能下载、能运行的中文 LLaMA2 模型

# 08. [基于 LLama2 的 QA 系统](https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference)

在本地CPU上运行Llama 2和其他开源LLM(Large Language Model)以实现文档问答。通过使用LLama 2、C Transformers、GGML和LangChain，可在本地部署开源LLM，减少对第三方提供商的依赖

# 07. [中文版 Llama2 模型及中英文 SFT 数据集](https://huggingface.co/LinkSoul/Chinese-Llama-2-7b)

# 06. [单样本微调给ChatGLM2注入知识](https://zhuanlan.zhihu.com/p/642357133)

[@Maeiee 微博](https://weibo.com/1240212845/NaDR5bf2x)：成功用 AdaLoRA 微调 ChatGLM2-6B，并让它掌握了一条新知识 @Funarp [笑而不语]

# 05. [MLC LLM项目: 个人设备上部署 LLM](https://github.com/mlc-ai/mlc-llm)

现在已经支持Llama-2，看Junru Shao在MacBook （M2max + 64G）上运行70B的模型速度还可以（ 7 tok/sec ）

MLC LLM 允许 LLLM 在 各种硬件后端 和 本机应用程序 上 进行本机部署，以及为每个人提供一个高效的框架，以进一步优化模型性能。

让每个人都能在每个人的设备上开发、优化和部署人工智能模型。

支持安卓、苹果等移动设备，还支持WebGPU on browsers

# 04. [Clippy：编程助手工具](https://github.com/ennucore/clippy)

基于GPT-4的多智能体协同工作，可以帮用户规划、编写、调试和测试项目代码，甚至可以自主完成一些项目

# 03. [Code Review GPT](https://github.com/mattzcarey/code-review-gpt)

由LLM(OpenAI GPT-3.5/4、Llama、Falcon、Azure AI)和Embedding支持的个人代码审查工具，可以在CI/CD流水线中用大型语言模型来审查代码，帮助提高代码质量并在代码投入生产之前捕捉错误，可检测常见问题，例如死代码、暴露秘密信息、缓慢或低效的代码和难以阅读的代码

# 02. [minigpt4.cpp：MiniGPT4的C++版](https://github.com/Maknee/minigpt4.cpp)

Port of MiniGPT4 in C++ (4bit, 5bit, 6bit, 8bit, 16bit CPU inference with GGML)

# 01. Memo（AI 驱动的视频、播客转文字、字幕工具 微博正文 ）技术实现

+ 使用的Electron构建，跨平台支持不错
+ 语音识别基于Whisper.CPP，Electron底层是Nodejs，Node对C++支持很好，但目前还没有直接的npm包支持whisper的，团队应该自己做了一些处理
+ 视频处理是基于ffmpeg和ffprobe，这两都有现成的npm包可用
+ 翻译支持Google和OpenAI，其中OpenAI是用的gpt-3.5-turbo-16k
+ Prompt比较简单：将字幕按行拼成字符串，每行前面加上序号，用一个one-shot示例，让它能按原始序号返回翻译后的结果。

这种翻译模式优缺点明显，优点就是经济实惠，缺点就是如果原始的字幕拆分不好，翻译后的结果不太容易对应回去，导致合并和漏行

