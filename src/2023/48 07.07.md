- [31. gotenberg: 基于 Docker 的生成 PDF 文件服务](#31-gotenberg-基于-docker-的生成-pdf-文件服务)
- [30. AFFiNE，类似 Notion 的协同知识库系统](#30-affine类似-notion-的协同知识库系统)
- [29. Open LLM API 开源大模型的统一后端接口，支持多种开源大模型](#29-open-llm-api-开源大模型的统一后端接口支持多种开源大模型)
- [28. 《AI Agents大爆发：软件2.0雏形初现，OpenAI的下一步》](#28-ai-agents大爆发软件20雏形初现openai的下一步)
- [26. Notion-to-Chatbot：允许你与任何 Notion 文档进行交谈](#26-notion-to-chatbot允许你与任何-notion-文档进行交谈)
- [25. LoRA 微调 LLM: ChatGLM2-6B / baichuan-7B / ChatGLM-6B](#25-lora-微调-llm-chatglm2-6b--baichuan-7b--chatglm-6b)
- [24. OpenResume: 简历生成器](#24-openresume-简历生成器)
- [23. Better Notes: 文献阅读 zotero-better-notes](#23-better-notes-文献阅读-zotero-better-notes)
- [22. GPT Migrate: 将代码项目迁移语言](#22-gpt-migrate-将代码项目迁移语言)
- [21. Byzer-LLM](#21-byzer-llm)
- [20. 简介：被 `Databricks` 收购的 `MosaicML`的 `MPT` 模型](#20-简介被-databricks-收购的-mosaicml的-mpt-模型)
- [19. 资讯：OpenAI 暂停了ChatGPT插件使用浏览器](#19-资讯openai-暂停了chatgpt插件使用浏览器)
- [18. 资讯：AI改变科研](#18-资讯ai改变科研)
- [17. `DragGAN-Windows-GUI`: `DragGAN` 的 windows 封装](#17-draggan-windows-gui-draggan-的-windows-封装)
- [16. 资讯：美国政府正准备限制中国企业使用美国云计算服务](#16-资讯美国政府正准备限制中国企业使用美国云计算服务)
- [15. `StyleDrop`：文本生成图像技术](#15-styledrop文本生成图像技术)
- [14. `Cotrans` 漫画/图片翻译器](#14-cotrans-漫画图片翻译器)
- [13. 观点：Prompt 是 LLM 的 粘性关键](#13-观点prompt-是-llm-的-粘性关键)
- [12. `MetaGPT`：多角色元编程框架](#12-metagpt多角色元编程框架)
- [11. `Statler`: 两个LLM，在无Context限制下进行长时间推理](#11-statler-两个llm在无context限制下进行长时间推理)
- [10. 本地文档对话：`MPT-30B` \& Langchain](#10-本地文档对话mpt-30b--langchain)
- [09. `Final2x`: 图像超分辨率提升](#09-final2x-图像超分辨率提升)
- [08. `Sweep AI`: 代码审查工具](#08-sweep-ai-代码审查工具)
- [07. HuggingFace 模型下载器](#07-huggingface-模型下载器)
- [06. `aider`: GPT操作编写代码和项目](#06-aider-gpt操作编写代码和项目)
- [05. OpenAI API: TopK \& Top P](#05-openai-api-topk--top-p)
- [04. `annie` \& `HeyPi`: 英语对话](#04-annie--heypi-英语对话)
- [03. 一丝清凉、或喜或悲：对当前大模型落地的几个有趣观点推介](#03-一丝清凉或喜或悲对当前大模型落地的几个有趣观点推介)
- [02. Midjourney WebUI](#02-midjourney-webui)
- [01. 小技巧：GPT Plus 翻译长文](#01-小技巧gpt-plus-翻译长文)

# 31. [gotenberg: 基于 Docker 的生成 PDF 文件服务](https://github.com/gotenberg/gotenberg)

+ 基于 Docker
+ 提供 API 和 Chromium / LibreOffice 交互
+ 将 HTML / Markdown / Word / Excel 变 PDF
# 30. [AFFiNE，类似 Notion 的协同知识库系统](https://hellogithub.com/repository/3e084ae1a0dc4a5199a20e71bbfc5d0a)

它拥有清爽、简洁的界面，支持离线使用。集成了笔记、知识库、数据表格等功能，同时这些内容之间还可以灵活组合。

# 29. [Open LLM API 开源大模型的统一后端接口，支持多种开源大模型](https://github.com/xusenlinzy/api-for-open-llm) 

# 28. [《AI Agents大爆发：软件2.0雏形初现，OpenAI的下一步》](https://mp.weixin.qq.com/s/Jb8HBbaKYXXxTSQOBsP5Wg)

英文原文：lilianweng.github.io/posts/2023-06-23-agent/

作者 Lilian Weng，OpenAI 的 Head of Safety Systems，之前还领导过 OpenAI 的 Applied AI 团队。

Lilian Weng 的这篇 Blog 可以说是目前 AI Agent 领域优质论文的系统综述，她将 Agents 定义为 LLM、记忆（Memory）、任务规划（Planning Skills）以及工具使用（Tool Use） 的集合，其中 LLM 是核心大脑，Memory、Planning Skills 以及 Tool Use 等则是 Agents 系统实现的三个关键组件，在文章中，她还对每个模块下实现路径进行了细致的梳理和说明。到今天，构建 AI Agent 的工具箱已经相对完善，但仍需要面对一些限制，例如上下文长度、长期规划和任务分解，以及 LLM 能力的稳定性等。

# 26. [Notion-to-Chatbot：允许你与任何 Notion 文档进行交谈](https://github.com/Anil-matcha/Notion-to-Chatbot/)

Notion-to-Chatbot：允许你与任何 Notion 文档进行交谈。

你可以轻松地输入你想要与之交谈的文档内容。它能够提供即时的答案，你可以提问、提取信息，甚至用 AI 对文档进行总结。

这个项目的源代码已经发布，你可以在 GitHub 上查看和使用。

# 25. [LoRA 微调 LLM: ChatGLM2-6B / baichuan-7B / ChatGLM-6B](https://github.com/beyondguo/LLM-Tuning)

对大模型的微调，把预训练模型微调为可对话的模型

# 24. [OpenResume: 简历生成器](https://github.com/xitanggg/open-resume)

在 GitHub 上看到一个功能强大的开源简历生成器： OpenResume。

拥有简洁美观的 UI 设计，并支持导入与解析 PDF 简历文件，实时更新简历数据，帮你快速撰写出清晰直观的个人简历。

# 23. [Better Notes: 文献阅读 zotero-better-notes](https://github.com/windingwind/zotero-better-notes)

GitHub 上看到一个比较实用的笔记插件：Better Notes，需搭配文献管理工具 Zotero 使用。

该插件开箱即用，集成了论文阅读、段落注释、做笔记、元数据分析、知识输出、AI 写作等功能。

插件完全开源、免费，支持双链笔记、Markdown 与标记语言，并深度集成了文献管理与阅读功能。收起

# 22. [GPT Migrate: 将代码项目迁移语言](https://github.com/0xpayne/gpt-migrate)

GPT Migrate，一个基于 GPT-4 的大胆尝试，让 AI 重写整个项目代码，实现所有代码框架、编程语言的迁移。

你可以将原有的 Python 项目，用 JavaScript 重写为新项目，AI 会自动帮你生成新的目录结构、文件命名、项目依赖包。

# 21. [Byzer-LLM](https://www.byzer.org/home)

未来的软件，应该都是这样的：左边软件界面，右边copilot

Byzer-LLM 就是那个可以让每个软件都有自己copilot的engine。 

# 20. [简介：被 `Databricks` 收购的 `MosaicML`的 `MPT` 模型](https://weibo.com/1912085257/N7xuguQJ2)

完全开源，支持商用，且技术领先。

MosaicML 的 MPT 大型语言模型 (LLM) 套件已经变得非常受欢迎。但是，是什么让这些模型如此特别呢？尽管 MPT 受欢迎的原因有多种，但我发现这些模型由于一些独特的组件而特别有用......

完全开源。 MPT型号，包括MPT-7B和MPT-30B，带有Apache 2.0许可证，这意味着它们可以不受任何限制地商业使用。此外，这些模型还附带一个完整的开源代码存储库，用于从头开始微调、评估甚至预训练这些模型（更多详细信息请参阅回复）。鉴于预训练基础 LLM 是任何基于 LLM 的系统中最令人望而却步/最昂贵的组成部分，MPT 基础系列是构建解决特定领域问题的专业 LLM 的一个很好的起点。

快速推理。 MPT 模型基于典型的仅解码器变压器架构。但是，他们对此架构进行了一些关键修改，包括：

+ 低精度图层规范
+ 闪光注意
+ ALiBi（而不是正常的位置嵌入）

由于这些修改，MPT 模型使用 HuggingFace 推理管道可以非常快速地执行推理（即比类似大小的 LLaMA 模型快 1.5-2 倍）。此外，MPT 模型与 FasterTransformer 等库完全兼容，可用于进一步提高推理速度。

上下文长度。由于使用了 ALiBi，MPT-7B 和 30B 能够处理大型上下文窗口，甚至可以推断出超出训练期间看到的数据的上下文长度。为了证明这一点，MPT-7B 对具有 64K 令牌上下文长度的数据进行了微调（源自 books3 小说小说语料库）。 MosaicML 的研究人员发现，该 MPT-StoryWriter-7B 模型能够处理较大的上下文长度，甚至可以进一步推断到高达 84K 的上下文窗口。他们甚至吸收了整本了不起的盖茨比书并生成了一个尾声！

表现。最后，MPT 模型表现非常好。 MPT-7B 在各种标准基准测试中的性能与 LLaMA-7B 相当。 MPT-30B 在基于文本的任务上的性能稍微落后于 LLaMA-30B 和 Falcon-40B，但它在编程任务上往往表现更好。另外，MPT-30B 的质量似乎超过了 GPT-3。简而言之，这些基本模型是高质量的，并为创建 ChatGPT 或 GPT-4 等专有系统的开源替代方案奠定了良好的基础。

# 19. 资讯：OpenAI 暂停了ChatGPT插件使用浏览器

OpenAI 暂停了ChatGPT插件使用浏览器的功能，因为在少量案例里，当用户要求ChatGPT访问一个链接并返回该网页里全部内容的时候ChatGPT可以突破这个链接的付费墙并搬回全文而这引起了一些内容创作者的惊讶和不满。

# 18. [资讯：AI改变科研](https://weibo.com/7755107971/4918118407471788)

感觉transformer至少首先是改变了科研届了。今天听说了一个应用的神奇案例，说我们隔壁组也是做机器学习和物理系的，观察某种宇宙粒子，但是这种宇宙粒子的出现比率是百万分之一，剩下都是白噪声。他们80年代搞了一个计算机，用特别老式的fortran写的代码，simulate这个东西。然后那个模拟器就一直用了40年了，一直没换过，现在没人知道那个机器背后的逻辑，但是还能用。然后今年他们用transformer模型，让Transformer去训练那个计算机生成出来的模拟数据，作为识别数据，来生成一些模拟的模拟数据，然后再部署到原本的那个模型里。发现transformer直接把这个百万分之一的生成原理学会了，生成出来的数据使得模型的表现提高了数倍。

我下一个项目可能也是做这个，根据日内瓦那个大型强子对撞机的那个数据来训练，生成一些高能粒子的运动轨迹数据，然后来对这个进行建模，原本这里是用贝叶斯和MCMC进行模拟，但是最近几个月我们组的所有导向几乎全都在谈论generative。

# 17. [`DragGAN-Windows-GUI`: `DragGAN` 的 windows 封装](https://github.com/zhaoyun0071/DragGAN-Windows-GUI)

DragGAN-Windows-GUI,DragGAN的windows封装。什么环境不用配置，解压直接用的dragGAN工具，内置17个模型。

DragGAN是通过拖动等方式对图中对象进行姿势、形状、表情和布局调整的AI工具

# 16. [资讯：美国政府正准备限制中国企业使用美国云计算服务](https://weibo.com/1627825392/N8iFI2GqN)

华尔街日报：拜登政府正准备限制中国企业使用美国云计算服务。若规定获通过，微软及亚马逊等美企在对中企提供相应服务前，将需要提前获得美国政府许可。预计商务部未来几周内公布细节。该限制措施被认为是修补漏洞，防止中企透过云服务使用英伟达(Nvidia)A100等计算芯片。 ​​​

# 15. [`StyleDrop`：文本生成图像技术](https://github.com/zideliu/StyleDrop-PyTorch)

`StyleDrop`，Google推出的一项新的文本生成图像技术。先给定一张特定风格的图片，然后用户输入的文本可以生产完全相同的风格的图片。

# 14. [`Cotrans` 漫画/图片翻译器](https://github.com/VoileLabs/cotrans)

`Cotrans` 漫画/图片翻译器 是一款可以直接翻译图片上的文字，并显示为中文的油猴脚本，支持 Pixiv，可以非常方便的看漫画、看图片

# 13. [观点：Prompt 是 LLM 的 粘性关键](https://weibo.com/1751401422/N8pUwsn1n)

所以对质量相仿的大模型来说，加强做Prompt工程培训可以加强用户粘性，并让用户用习惯性Prompt提问其他大模型时产生其他大模型不如自己的初次印象

有个观点：大模型底座是没有任何粘性的，很容易被替换。

你当prompt是通用么？就像不同数据库有不同的SQL方言，不同的大模型也会有不同的prompt,而且区别会比SQL方言大多了（因为Prompt灵活性也更高）。

企业一旦使用一个大模型，就会有大量的Prompt投入在这个模型上，一个系统可能会有成千上万的prompt， 你告诉我能轻松切？

切了瞬间让你系统效果大跌。而且Prompt这玩意是个实验工程，虽然使用门槛降低了，但是反倒要比SQL这样明确的语言花更多时间。

# 12. [`MetaGPT`：多角色元编程框架](http://github.com/geekan/MetaGPT)

`MetaGPT`：多角色元编程框架，使 GPT 能够以软件公司的形式工作，协作处理更复杂的任务

# 11. [`Statler`: 两个LLM，在无Context限制下进行长时间推理](https://arxiv.org/abs/2306.17840)

`Statler`是一个新框架，通过使用两个实例的大型语言模型——世界模型读取器和世界模型写入器——来维护和接口交互世界状态，从而提高了机器人在没有上下文长度限制的情况下进行长时间推理的能力。

# 10. [本地文档对话：`MPT-30B` & Langchain](https://github.com/mayooear/private-chatbot-mpt30b-langchain)

用 MPT-30B & Langchain实现的本地版文档对话引擎，支持8k上下文，可保护隐私

# 09. [`Final2x`: 图像超分辨率提升](https://github.com/Tohrusky/Final2x)

Final2x：将图像超分辨率提升到任意大小，旨在提高图像的分辨率和质量，使其更清晰、更详细，支持多个模型

# 08. [`Sweep AI`: 代码审查工具](https://github.com/sweepai/sweep)

Sweep允许您轻松创建和查看 GitHub 问题。只需描述任何问题，Sweep 就会完成剩下的工作。它将计划需要做什么、要进行哪些更改，并将更改写入 PR。

支持的语言：Python、Javascript/Typescript、Rust、Go、Java/C#、C++ 以及 GPT-4 支持的任何其他语言

# 07. [HuggingFace 模型下载器](https://github.com/bodaay/HuggingFaceModelDownloader)

HuggingFace Model Downloader：HuggingFace模型下载器，从HuggingFace网站下载模型/数据集的实用工具，提供了多线程下载LFS文件的能力，并通过检查SHA256校验和确保已下载模型的完整性

# 06. [`aider`: GPT操作编写代码和项目](https://github.com/paul-gauthier/aider)

aider ，是一个命令行聊天工具，允许您使用 OpenAI 的 GPT 模型编写和编辑代码。

您可以要求 GPT 帮助您启动新项目，或修改现有 git 存储库中的代码。 Aider 可以轻松地进行 git commit、diff 和撤消 GPT 提出的更改，而无需复制/粘贴。它还具有帮助 GPT-4 理解和修改更大代码库的功能

# 05. [OpenAI API: TopK & Top P](https://weibo.com/1727858283/N7YiqvQcm)

例子：如果P是0.85，那么就是从第一个开始往后累加，直到超过0.85，然后从这前n个总和超过0.85的词里面选一个

Top K 可以让模型从可能性最高的前 K 个词中随机返回一个词，这种方法可以让模型不会总是选概率最高的那个，而是从概率最高的前K个词中随机选择一个词。

但这种方法有一个缺陷，比如说你指定Top K是3，但如果概率最高的前3个词里面，第3个词其实概率很低相关度很弱，那么就会导致生成的结果不够好。

Top P则是另一种选择方式，让模型可以从一组总和不超过 P 的词中选择。

例如，Top P为0.75意味着你从一组累积概率大于0.75的词中取样。这样可以避免概率很低的词被选中。

# 04. [`annie` & `HeyPi`: 英语对话](https://weibo.com/1727858283/N7ZXNc4Ms)

除了Call Annie外，还有一个 HeyPi （heypi.com）是很适合联系英语对话和听力的
网页链接

这是一个公认很会聊天的AI，不用担心把天聊死了，并且它支持文字和语音。语音输入需要借助苹果系统自带的输入。

注册略微有点麻烦，不能直接支持国内手机号，可以借助 sms-activate.org （“选择服务”搜索 other，挑一个英国虚拟号，大概要花费人民币1元钱）这样的平台

# 03. [一丝清凉、或喜或悲：对当前大模型落地的几个有趣观点推介](https://mp.weixin.qq.com/s/sc4JvTQZPlZFreCTFUbUiQ?mark_id=999_reallog_mark_ad%3A999%7CWeiboADNatural)

这篇文章写得很不错，里面也提到了关于向量数据库和Embedding，以及它们和这一波LLM的关系………其中有一些少有人能够认知和愿意说的真相，借着它展开说说：

1. 向量数据库不是 Long-term Memory

向量数据库不能解决LLM上下文限制的根本问题，而把太长的原始文档切分后，根据用户问题检索后，只喂一部分文档给LLM进行回答，这种方案会严重降低LLM的回答质量（包括完整性，逻辑性 & 准确性……）。用户如果了解内幕，会知道这是外围方案的问题，如果不知道，会以为是LLM不行。所以……如果不想让用户觉得你的LLM不行，那么不要太倚重这种外围技术。

2. Embedding和GPT

Embedding其实是个古老的技术，借助Embedding提取文本的向量表示后，可以进行NLP的相关Task，包括聚类，分词，相关性分析等等，这些也都是有年代的古远技术。

GPT内部是用到了Embedding，但是和传统意义上完整Embedding接口不同，它只是很浅的一层，用于捕获单词之间的语义关系和语法信息，作为模型内部的词表示，供模型后面的Transformer架构继续处理，它并不是GPT的重点和核心技术。

而GPT提供的外部Embedding接口，则是传统意义上的向量化接口，由于模型的特点，用得好的话会比与普通的词向量表示方法（如Word2Vec、GloVe）等，会有更好的上下文捕获功能等优势（收费也不便宜，也有竞品）。但是如果觉得，借助这些接口对文档进行向量化，加上外部的工程化，进行相似度比较和检索等，就可以获得等同于GPT的能力，那又是太天真了。


# 02. [Midjourney WebUI](https://weibo.com/1727858283/N842inf2X)

Midjourney 终于推出WebUI了，不再需要通过Discord聊天的方式。但还在测试中，只有你用MJ画过超过10000张图的才有资格测试。

不需要输入/imagine，写提示方便多了
可以自定义工作区
可以直接上传图片
可以查看生成历史
有提示栏功能，帮助生成随机提示

有兴趣的同学可以看图3中网友歸藏（ twitter.com/op7418 ）的总结

# 01. [小技巧：GPT Plus 翻译长文](https://weibo.com/1727858283/N84axBq8O)

一个使用ChatGPT Plus翻译长文的小技巧，可以绕开ChatGPT的输入框的长度限制，避免手动分段复制粘贴。

注意需要ChatGPT Plus和ChatGPT插件，按照以下步骤操作：

步骤一：将你要翻译的长文放在一个公网可以访问到的网址，比如我是使用的GitHub的gist，最好只显示你要翻译的内容

步骤二：在ChatGPT Plus中启用WebPilot插件

步骤三：直接用Prompt让ChatGPT翻译指定的URL。

然后就可以ChatGPT会自动把所有内容都翻译完成。但总长度还是无法超过8K的限制，如果很长，还是要手动拆分，但这样已经方便很多了。
