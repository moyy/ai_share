- [AI: 2023.09](#ai-202309)
- [1. 工具](#1-工具)
  - [1.1. Elicit: 加入LLM文本总结功能 的 论文检索网站](#11-elicit-加入llm文本总结功能-的-论文检索网站)
  - [1.2. Pulse 用AI还原低分辨率图像细节的工具](#12-pulse-用ai还原低分辨率图像细节的工具)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.1. `MindsDB` 将 AI 模型连接到数据库](#21-mindsdb-将-ai-模型连接到数据库)
  - [2.2. `ChatDev`: 多个大模型驱动的智能体协同进行全流程自动化软件开发框架](#22-chatdev-多个大模型驱动的智能体协同进行全流程自动化软件开发框架)
  - [2.3. Open Interpreter，让大语言模型在您的计算机上运行代码](#23-open-interpreter让大语言模型在您的计算机上运行代码)
- [3. 模型](#3-模型)
  - [3.1. 用 投机采样（Speculative Sampling） 提升 推理效率](#31-用-投机采样speculative-sampling-提升-推理效率)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.1. 《基于大语言模型的AI Agents—Part 2》](#41-基于大语言模型的ai-agentspart-2)
  - [4.2. Quora: 为什么GPU特适合深度学习？](#42-quora-为什么gpu特适合深度学习)
  - [4.3. 图模型 列表](#43-图模型-列表)
- [5. 资讯 / 观点](#5-资讯--观点)
- [5.1. 论文 CityDreamer：无界 3D 城市的组合生成模型](#51-论文-citydreamer无界-3d-城市的组合生成模型)

# AI: 2023.09

# 1. 工具

## 1.1. [Elicit: 加入LLM文本总结功能 的 论文检索网站](https://beta.elicit.org)

+ 用白话文，输入想要解决某个问题
+ 网站返回 8 篇相关论文及其总结
+ 并将这 8 篇归类，再给你一个总结
+ 这些论文通过 DOI 可以下载 PDF

## 1.2. [Pulse 用AI还原低分辨率图像细节的工具](https://github.com/adamian98/pulse)

严格来说，不能叫做还原，而是扩充，对于图像缺失的信息，AI 是无法做到准确还原的，它的用途在于探索图像中缺失信息的可能性，然后逐一还原成清晰图像，

例如，用户输入一张 16x16 分辨率的图像，利用 Pulse 可以输出一组 1024x1024 分辨率的图像

背后用到的是 StyleGan 这个图像生成模型，


# 2. 项目 / 框架

## 2.1. [`MindsDB` 将 AI 模型连接到数据库](https://github.com/mindsdb/mindsdb)

MindsDB 的 AI 虚拟数据库使开发人员能够将任何 AI/ML 模型连接到任何数据源。这包括关系型和非关系型数据库、数据仓库和 SaaS 应用程序。 

+ 通过“增强的 SQL”抽象创建和管理 AI 模型（基于 LLM 的语义搜索和 QnA、时间序列预测、异常检测、分类、推荐等）。
+ 根据其支持的 130 多个数据源中包含的数据自动训练和微调 AI 模型。
+ 接入人工智能模型，使其在观察到新数据时自动运行，并将输出插入到我们的任何集成中。

## 2.2. [`ChatDev`: 多个大模型驱动的智能体协同进行全流程自动化软件开发框架](https://github.com/OpenBMB/ChatDev)

#LLM群体智能# 单体大模型的能力大家有目共睹，那一群大模型会怎样？团队同学近期探索了让多个大模型驱动的智能体协同进行全流程自动化软件开发框架ChatDev 🤖(Chat-powered Software Development) 。ChatDev模拟一个由多智能体协作运营的虚拟软件公司，在人类“用户”指定一个具体的任务需求指令下，不同角色的智能体将通过多环节进行语言交互式协同，产出一个完整软件（包括源代码、环境依赖说明书、用户手册等）。

核心理念💡：通过对瀑布模型的分解，形成由原子任务构成的交流链(Chat Chain)，链中每个子任务通过专业角色（例如产品设计官、Python程序员、测试工程师、文档撰写员等）的智能体进行语言交互式信息传递和决策；驱动其进行自动化需求分析、创意脑暴、系统开发、集成测试、GUI创作、文档编制等全流程软件工程。ChatDev的软件制作平均时间小于7.0分钟⏰且制作成本约$0.3刀💰（即买一杯可乐🥤的价格并喝完它的时间）。

## 2.3. [Open Interpreter，让大语言模型在您的计算机上运行代码](https://github.com/KillianLucas/open-interpreter)

类似openai的代码解释器功能但是在本地运行

# 3. 模型

## 3.1. [用 投机采样（Speculative Sampling） 提升 推理效率](https://mp.weixin.qq.com/s/VXiby6fUCWJEP3fsqHbTEw)

开源社区的一位开发者Georgi Gerganov发现，自己可以在M2 Ultra上运行全F16精度的34B Code Llama模型，而且推理速度超过了20 token/s。

毕竟，M2 Ultra的带宽有800GB/s。其他人通常需要4个高端GPU才能做到！

# 4. 技巧 / 教程

## 4.1. [《基于大语言模型的AI Agents—Part 2》](https://www.breezedeus.com/article/ai-agent-part2)

## 4.2. [Quora: 为什么GPU特适合深度学习？](https://weibo.com/1402400261/NhQd98t1N)

《Tim Dettmers's answer to Why are GPUs well-suited to deep learning? - Quora》 

+ GPU相较于CPU更快的原因在于其高效的矩阵乘法和卷积运算，但很少有人解释了为什么会如此。
+ GPU之所以快，是因为其内存带宽，而不仅仅是并行计算。CPU以低延迟为优化目标，而GPU则以`高带宽`为优化目标。
+ CPU可以迅速获取RAM中的少量内存(包)，而GPU在此方面速度较慢(延迟较高)。然而，GPU可以`一次获取更多的内存`。
+ GPU之所以能在大内存块上提供最佳内存带宽，是因为线程并行性掩盖了延迟，使得GPU在大数据块上提供高带宽，同时不受延迟的影响。
+ GPU的寄存器内存比CPU多30多倍，速度则达到了两倍。这意味着GPU`可以存储大量数据在寄存器和L1缓存`中，以便复用卷积和矩阵乘法的片。
+ GPU的寄存器和L1缓存更易于编程，这使得它们在深度学习中非常适用。
+ 性能瓶颈主要取决于内存访问，因此GPU之所以快速适用于深度学习，是因为其高带宽主存储、线程并行性隐藏内存访问延迟，以及大而快的寄存器和L1缓存。

## 4.3. [图模型 列表](https://github.com/THUMNLab/awesome-large-graph-model)

# 5. 资讯 / 观点

# 5.1. 论文 [CityDreamer：无界 3D 城市的组合生成模型](https://github.com/hzxie/city-dreamer/)

近年来，广泛的研究集中在 3D 自然场景生成上，但 3D 城市生成领域还没有得到太多的探索。这是由于3D城市生成带来了更大的挑战，主要是因为人类对城市环境的结构扭曲更加敏感。此外，生成 3D 城市比 3D 自然场景更复杂，因为与自然场景中树木等对象相对一致的外观相比，建筑物作为同一类对象表现出更广泛的外观。

为了应对这些挑战，我们提出了 CityDreamer，这是一种专门为无界 3D 城市设计的组合生成模型，它将建筑实例的生成与其他背景对象（例如道路、绿地和水域）分离成不同的模块。此外，我们构建了两个数据集 OSM 和 GoogleEarth，其中包含大量真实世界的城市图像，以增强生成的 3D 城市布局和外观的真实感。

通过大量的实验，CityDreamer 证明了其在生成各种逼真的 3D 城市方面优于最先进的方法。

