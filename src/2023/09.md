#! https://zhuanlan.zhihu.com/p/659226348
- [AI: 2023.09](#ai-202309)
- [1. 工具](#1-工具)
  - [1.1. Elicit: 加入LLM文本总结功能 的 论文检索网站](#11-elicit-加入llm文本总结功能-的-论文检索网站)
  - [1.2. Pulse 用AI还原低分辨率图像细节的工具](#12-pulse-用ai还原低分辨率图像细节的工具)
  - [1.3. `Hiber3D` 推出的一款工具，可以使用自然语言生成3D世界](#13-hiber3d-推出的一款工具可以使用自然语言生成3d世界)
  - [1.4.`Procreate Dreams`：动画设计 iPad App（价格: $19.99, 11.22号 发布）](#14procreate-dreams动画设计-ipad-app价格-1999-1122号-发布)
  - [1.5. `Meshy`: AI工具箱，比如：文本/图像 生成3D模型](#15-meshy-ai工具箱比如文本图像-生成3d模型)
  - [1.6. OpenAI视觉 GPT-4v](#16-openai视觉-gpt-4v)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.1. `MindsDB` 将 AI 模型连接到数据库](#21-mindsdb-将-ai-模型连接到数据库)
  - [2.2. `ChatDev`: 多个大模型驱动的智能体协同进行全流程自动化软件开发框架](#22-chatdev-多个大模型驱动的智能体协同进行全流程自动化软件开发框架)
  - [2.3. Open Interpreter，让大语言模型在您的计算机上运行代码](#23-open-interpreter让大语言模型在您的计算机上运行代码)
  - [2.4. `AgentVerse` 清华 / 北邮 等 高校 发布 AI 多智能体 协作 模拟框架](#24-agentverse-清华--北邮-等-高校-发布-ai-多智能体-协作-模拟框架)
  - [2.5. MindChat: 心理大模型](#25-mindchat-心理大模型)
  - [2.6. 微软 开源 Prompt flow，可用于简化大模型应用的开发周期](#26-微软-开源-prompt-flow可用于简化大模型应用的开发周期)
- [3. 模型](#3-模型)
  - [3.1. 用 投机采样（Speculative Sampling） 提升 推理效率](#31-用-投机采样speculative-sampling-提升-推理效率)
  - [3.2. Pai-Megatron-Patch：阿里云智算服务PAI-灵骏平台 LLM 最佳实践](#32-pai-megatron-patch阿里云智算服务pai-灵骏平台-llm-最佳实践)
  - [3.3. CodeFuse-MFTCoder: 多任务微调代码大模型，包含代码大模型的模型、数据、训练等](#33-codefuse-mftcoder-多任务微调代码大模型包含代码大模型的模型数据训练等)
  - [3.4. ExLlamaV2: 在消费GPU上推理LLM](#34-exllamav2-在消费gpu上推理llm)
  - [3.5. 智源研究院 开源 Embedding: 将任意文本映射为低维稠密向量](#35-智源研究院-开源-embedding-将任意文本映射为低维稠密向量)
  - [3.6. Mistral AI 开源 `Mistral 7B` 所有基准测试中优于 Llama 2 13B](#36-mistral-ai-开源-mistral-7b-所有基准测试中优于-llama-2-13b)
  - [3.7. 用强化学习提升扩散模型](#37-用强化学习提升扩散模型)
  - [3.8. 基于 LLaMA-2 的 中文大模型](#38-基于-llama-2-的-中文大模型)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.1. 《基于大语言模型的AI Agents—Part 2》](#41-基于大语言模型的ai-agentspart-2)
  - [4.2. Quora: 为什么GPU特适合深度学习？](#42-quora-为什么gpu特适合深度学习)
  - [4.3. 图模型 列表](#43-图模型-列表)
  - [4.4. 最近一个月整理的 RAG 领域知识库](#44-最近一个月整理的-rag-领域知识库)
  - [4.5. LLM Agents 最新动态](#45-llm-agents-最新动态)
- [5. 资讯 / 观点](#5-资讯--观点)
  - [5.1. 论文 CityDreamer：无界 3D 城市的组合生成模型](#51-论文-citydreamer无界-3d-城市的组合生成模型)
  - [5.2. 观点 LLM没有 推理 \& 规划 能力](#52-观点-llm没有-推理--规划-能力)
  - [5.3. 观点 微调Llama 2替代GPT-3.5/4到底值不值](#53-观点-微调llama-2替代gpt-354到底值不值)
  - [5.4. 资讯 在线游戏平台 Roblox 发布 名为 Roblox Assistant 的新型AI聊天机器人，让创作者只需输入提示即可构建虚拟世界](#54-资讯-在线游戏平台-roblox-发布-名为-roblox-assistant-的新型ai聊天机器人让创作者只需输入提示即可构建虚拟世界)

# AI: 2023.09

# 1. 工具

## 1.1. [Elicit: 加入LLM文本总结功能 的 论文检索网站](https://beta.elicit.org)

+ 用白话文，输入想要解决某个问题
+ 网站返回 8 篇相关论文及其总结
+ 并将这 8 篇归类，再给你一个总结
+ 这些论文通过 DOI 可以下载 PDF

## 1.2. [Pulse 用AI还原低分辨率图像细节的工具](https://github.com/adamian98/pulse)

严格来说，不能叫做还原，而是扩充，对于图像缺失的信息，AI 是无法做到准确还原的，它的用途在于探索图像中缺失信息的可能性，然后逐一还原成清晰图像，

例如，用户输入一张 16x16 分辨率的图像，利用 Pulse 可以输出一组 1024x1024 分辨率的图像

背后用到的是 StyleGan 这个图像生成模型，

## 1.3. [`Hiber3D` 推出的一款工具，可以使用自然语言生成3D世界](https://www.hiber3d.com/genai)

可以直接发布到网页上，并且能在各种设备上运行，包括移动设备、平板电脑和桌面电脑。

## 1.4.[`Procreate Dreams`：动画设计 iPad App（价格: $19.99, 11.22号 发布）](https://procreate.com/cn/dreams)

这款应用提供了一整套强大的动画工具，包括高级关键帧、触摸式操作流程、简易逐帧编辑，以及音频和视频的支持。

这款应用程序是一个全方位的动画制作工具，无论你是专业人士还是初学者，都能找到适合自己的功能。

主要功能:

+ **高级关键帧制作**：用于定义动画中的主要动作点。
+ **触摸式操作流程**：直观地控制动画的每一个细节。
+ **简易逐帧编辑**：方便地编辑每一帧来创建流畅的动画。
+ **音频和视频支持**：可以导入和编辑音频和视频，增加戏剧性和表现力。
+ **多点触控时间轴**：专为动画设计的时间轴，支持多点触控。
+ **实时动态和特效**：可以实时预览动画效果。
+ **文本与字形设计**：支持制作文字动画和导入自定义字体。
+ **iCloud 支持**：方便的文件管理和备份。
+ **自动保存**：你操作的每个步骤都会立即保存，避免数据丢失。
+ **专为 iPad 和 Apple Pencil 打造**：提供无与伦比的触控和绘画体验。

## 1.5. [`Meshy`: AI工具箱，比如：文本/图像 生成3D模型](http://Meshy.ai)

+ 2D图像转3D纹理：只需输入一个图像，AI会在不到15分钟内自动将2D转换为3D。
+ 文本提示到纹理：即使没有任何3D经验的创作者也可以使用文本输入来生成3D游戏资产，所有这些都在2分钟内完成。
+ AI 3D纹理工具：允许选择文本提示或2D概念艺术，以及一个未纹理的模型作为输入。AI将在不到3分钟内为你的模型进行自动纹理。

## 1.6. OpenAI视觉 GPT-4v

+ GPT-4V是OpenAI开发的多模态模型，可接受文本和图像作为输入，进行视觉问答。   
+ GPT-4V在一般的图像问答方面表现不错，能理解图像的上下文。但也存在一些限制，如会“幻觉”，给出不准确的信息。   
+ GPT-4V目前无法准确给出目标检测的边界框，表明其目前不适合这种用例。   
+ GPT-4V无法回答有关人物的问题。当给出Taylor Swift的照片时，它拒绝回答图片中的是谁。   
+ GPT-4V在读懂图像文字方面表现很好，但对于角度变化和对比度较弱的文字识别能力较弱。   
+ GPT-4V可以正确读取数学题并解答，但可能会错过一些数学符号。   
+ GPT-4V可以识别填字游戏和数独，但无法正确理解格子结构，导致解答错误。   
+ OpenAI对GPT-4V进行了安全性研究，发现了一些风险，并尝试进行缓解，但仍有进一步改进的空间。

# 2. 项目 / 框架

## 2.1. [`MindsDB` 将 AI 模型连接到数据库](https://github.com/mindsdb/mindsdb)

MindsDB 的 AI 虚拟数据库使开发人员能够将任何 AI/ML 模型连接到任何数据源。这包括关系型和非关系型数据库、数据仓库和 SaaS 应用程序。 

+ 通过“增强的 SQL”抽象创建和管理 AI 模型（基于 LLM 的语义搜索和 QnA、时间序列预测、异常检测、分类、推荐等）。
+ 根据其支持的 130 多个数据源中包含的数据自动训练和微调 AI 模型。
+ 接入人工智能模型，使其在观察到新数据时自动运行，并将输出插入到我们的任何集成中。

## 2.2. [`ChatDev`: 多个大模型驱动的智能体协同进行全流程自动化软件开发框架](https://github.com/OpenBMB/ChatDev)

#LLM群体智能# 单体大模型的能力大家有目共睹，那一群大模型会怎样？团队同学近期探索了让多个大模型驱动的智能体协同进行全流程自动化软件开发框架ChatDev 🤖(Chat-powered Software Development) 。ChatDev模拟一个由多智能体协作运营的虚拟软件公司，在人类“用户”指定一个具体的任务需求指令下，不同角色的智能体将通过多环节进行语言交互式协同，产出一个完整软件（包括源代码、环境依赖说明书、用户手册等）。

核心理念💡：通过对瀑布模型的分解，形成由原子任务构成的交流链(Chat Chain)，链中每个子任务通过专业角色（例如产品设计官、Python程序员、测试工程师、文档撰写员等）的智能体进行语言交互式信息传递和决策；驱动其进行自动化需求分析、创意脑暴、系统开发、集成测试、GUI创作、文档编制等全流程软件工程。ChatDev的软件制作平均时间小于7.0分钟⏰且制作成本约$0.3刀💰（即买一杯可乐🥤的价格并喝完它的时间）。

## 2.3. [Open Interpreter，让大语言模型在您的计算机上运行代码](https://github.com/KillianLucas/open-interpreter)

类似openai的代码解释器功能但是在本地运行

## 2.4. [`AgentVerse` 清华 / 北邮 等 高校 发布 AI 多智能体 协作 模拟框架](https://github.com/OpenBMB/AgentVerse)

它可以很容易的模拟多种社会实验场景，例如：NLP课堂、囚徒困境、软件设计、数据库诊断、Pokeman等。

## 2.5. [MindChat: 心理大模型](https://github.com/X-D-Lab/MindChat)

期望从心理咨询、心理评估、心理诊断、心理治疗四个维度帮助人们纾解心理压力与解决心理困惑, 提高心理健康水平 

## 2.6. [微软 开源 Prompt flow，可用于简化大模型应用的开发周期](https://github.com/microsoft/promptflow)

打通了从项目构思、原型设计、测试、评估到生产部署和监控的全流程，让开发者可以快速构建出高质量的大语言模型应用。

# 3. 模型

## 3.1. [用 投机采样（Speculative Sampling） 提升 推理效率](https://mp.weixin.qq.com/s/VXiby6fUCWJEP3fsqHbTEw)

开源社区的一位开发者Georgi Gerganov发现，自己可以在M2 Ultra上运行全F16精度的34B Code Llama模型，而且推理速度超过了20 token/s。

毕竟，M2 Ultra的带宽有800GB/s。其他人通常需要4个高端GPU才能做到！

## 3.2. [Pai-Megatron-Patch：阿里云智算服务PAI-灵骏平台 LLM 最佳实践](https://github.com/alibaba/Pai-Megatron-Patch)

旨在帮助大模型开发者快速上手灵骏产品，完成大语言模型(LLM)的高效分布式训练，有监督指令微调，模型离线推理验证等完整大模型开发链路

## 3.3. [CodeFuse-MFTCoder: 多任务微调代码大模型，包含代码大模型的模型、数据、训练等](https://github.com/codefuse-ai/MFTCoder)

## 3.4.[ ExLlamaV2: 在消费GPU上推理LLM](https://github.com/turboderp/exllamav2)

## 3.5. [智源研究院 开源 Embedding: 将任意文本映射为低维稠密向量](https://github.com/FlagOpen/FlagEmbedding)

## 3.6. [Mistral AI 开源 `Mistral 7B` 所有基准测试中优于 Llama 2 13B](https://mistral.ai/news/announcing-mistral-7b/)

以用于检索、分类、聚类或语义匹配等任务，并可支持为大模型调用外部知识。

## 3.7. [用强化学习提升扩散模型](https://carper.ai/enhancing-diffusion-models-with-reinforcement-learning/)

+ CarperAI发布了DRLX库，用强化学习训练扩散模型，目前实现了最新的DDPO算法。   
+ 奖励模型输出可以看作是对一个生成内容相对于另一个生成内容被人类选择的对数几率。   
+ DDPO算法将扩散模型形式化为马尔可夫决策过程，可以应用策略梯度方法进行强化学习微调。   
+ 使用DRLX库和审美评分器对Stable Diffusion 2.1进行了DDPO训练，结果生成了更美观但多样性较弱的图像。   
+ 使用PickScore而不是审美评分器作为奖励模型进行了DDPO训练，可以产生更符合提示的图像。   
+ 图像生成的强化学习仍有大量工作要做，包括尝试不同的算法，改进奖励模型等。

## 3.8. [基于 LLaMA-2 的 中文大模型](https://github.com/hpcaitech/ColossalAI)

Colossal-AI 利用 LLaMA-2 的基础能力，仅使用约 8.5B token 数据、15 小时、数千元的训练成本，成功构建了性能卓越的中文 LLaMA-2，在多个评测榜单性能优越。

相较于原始 LLaMA-2，在成功提升中文能力的基础上，进一步提升其英文能力，性能可与开源社区同规模预训练 SOTA 模型媲美。

# 4. 技巧 / 教程

## 4.1. [《基于大语言模型的AI Agents—Part 2》](https://www.breezedeus.com/article/ai-agent-part2)

## 4.2. [Quora: 为什么GPU特适合深度学习？](https://weibo.com/1402400261/NhQd98t1N)

《Tim Dettmers's answer to Why are GPUs well-suited to deep learning? - Quora》 

+ GPU相较于CPU更快的原因在于其高效的矩阵乘法和卷积运算，但很少有人解释了为什么会如此。
+ GPU之所以快，是因为其内存带宽，而不仅仅是并行计算。CPU以低延迟为优化目标，而GPU则以`高带宽`为优化目标。
+ CPU可以迅速获取RAM中的少量内存(包)，而GPU在此方面速度较慢(延迟较高)。然而，GPU可以`一次获取更多的内存`。
+ GPU之所以能在大内存块上提供最佳内存带宽，是因为线程并行性掩盖了延迟，使得GPU在大数据块上提供高带宽，同时不受延迟的影响。
+ GPU的寄存器内存比CPU多30多倍，速度则达到了两倍。这意味着GPU`可以存储大量数据在寄存器和L1缓存`中，以便复用卷积和矩阵乘法的片。
+ GPU的寄存器和L1缓存更易于编程，这使得它们在深度学习中非常适用。
+ 性能瓶颈主要取决于内存访问，因此GPU之所以快速适用于深度学习，是因为其高带宽主存储、线程并行性隐藏内存访问延迟，以及大而快的寄存器和L1缓存。

## 4.3. [图模型 列表](https://github.com/THUMNLab/awesome-large-graph-model)

## 4.4. [最近一个月整理的 RAG 领域知识库](https://potato-workspace.notion.site/RAG-e55cf4c487c147fbbb824ffb6b899e49?pvs=4)

目前已收录 105 篇相关技术文章及视频，包括：概述、检索、分块、混合搜索、微调、评估、知识图谱、重排序、元数据过滤、向量数据库、合成器、代理，一共 12 个分类，仍在更新中。

## 4.5. [LLM Agents 最新动态](https://github.com/WooooDyy/LLM-Agent-Paper-List)

“我们从基于LLM的智能体的一般概念框架开始：包括三个主要组成部分：大脑、感知和行动，并且该框架可以根据不同的应用进行定制。”

长期以来，人类一直在追求相当于或超越人类水平的人工智能（AI），而人工智能代理被认为是实现这一追求的有前途的工具。人工智能代理是感知环境、做出决策并采取行动的人造实体。

由于它们表现出的多功能和卓越的能力，大语言模型（LLM）被认为是通用人工智能（AGI）的潜在火花，为构建通用人工智能代理带来了希望。许多研究工作都利用LLM作为构建人工智能代理的基础，并取得了重大进展。

在此存储库中，我们对基于 LLM 的代理进行了系统且全面的调查，并列出了一些必读论文。

具体来说，我们从基于LLM的代理的一般概念框架开始：包括三个主要组件：大脑、感知和行动，并且该框架可以定制以适应不同的应用。随后，我们探讨了基于LLM的智能体在单智能体场景、多智能体场景和人与智能体合作三个方面的广泛应用。接下来，我们深入研究代理人社会，探讨LLM代理人的行为和个性，他们形成社会时出现的社会现象，以及他们为人类社会提供的见解。最后，我们讨论该领域内的一系列关键主题和开放问题。

# 5. 资讯 / 观点

## 5.1. 论文 [CityDreamer：无界 3D 城市的组合生成模型](https://github.com/hzxie/city-dreamer/)

近年来，广泛的研究集中在 3D 自然场景生成上，但 3D 城市生成领域还没有得到太多的探索。这是由于3D城市生成带来了更大的挑战，主要是因为人类对城市环境的结构扭曲更加敏感。此外，生成 3D 城市比 3D 自然场景更复杂，因为与自然场景中树木等对象相对一致的外观相比，建筑物作为同一类对象表现出更广泛的外观。

为了应对这些挑战，我们提出了 CityDreamer，这是一种专门为无界 3D 城市设计的组合生成模型，它将建筑实例的生成与其他背景对象（例如道路、绿地和水域）分离成不同的模块。此外，我们构建了两个数据集 OSM 和 GoogleEarth，其中包含大量真实世界的城市图像，以增强生成的 3D 城市布局和外观的真实感。

通过大量的实验，CityDreamer 证明了其在生成各种逼真的 3D 城市方面优于最先进的方法。

## 5.2. 观点 [LLM没有 推理 & 规划 能力](https://cacm.acm.org/blogs/blog-cacm/276268-can-llms-really-reason-and-plan/fulltext)

从以下几方面 阐释了 LLM模型并不真正具有推理和规划能力:

+ LLM模型的训练和使用过程中没有任何迹象表明其可以进行原则性的推理，这通常需要计算上十分困难的推断/搜索。一些文章声称LLM有零样本推理能力，但这些结论值得怀疑。   
+ 对GPT-3、GPT-3.5和GPT-4在规划任务上的测试表明，尽管性能有所提升，但GPT-4的规划准确率只有30%左右，在其他领域更低们进一步通过打乱动作和对象名称来测试，GPT-4的性能大幅下降，表明其并不能真正进行规划。  
+ 通过巧妙提示或自训练来提升LLM的规划能力的做法也存在问题。人工提示会产生Clever Hans效应，模型自训练也需要假设模型的解验证比解生成更加容易，这些假设都无法证明。   
+ 一些文章声称LLM有规划能力，但在仔细检验下，这些所谓的规划往往只是提取了规划知识，而非真正可执行的规划。执行时的子目标交互往往被忽略或者转由人工完成。 
+ LLM的价值在于可以提取规划知识，生成规划思路，但需要人工或专门的程序来验证和完善这些知识和思路，最后交给基于模型的规划器来保证正确性。这与过去的知识工程方法有相似之处。   
+ 总之，没有任何证据表明LLM真正具备推理和规划能力。它们通过大规模训练进行的是一种普适的近似检索，有时会被误认为是推理能力。不应当过于夸大LLM的能力，但可以充分利用其生成思路的优势来辅助推理和规划。  

## 5.3. 观点 [微调Llama 2替代GPT-3.5/4到底值不值](https://news.ycombinator.com/item?id=37484135)

+ 个人和小公司可以通过微调开源语言模型如Llama 2来替代GPT-3.5/4，从而显著降低成本。有人提供了示例notebook以指导如何标注数据、进行微调和运行高效推理。通过对7B模型的微调，可以达到和GPT-4相当的效果，但成本只有GPT-3.5的1/50。   
+ 微调对指导模型行为更有效，所以可以用更小的模型达到同等效果，从而加快响应速度和降低推理成本。但是启动微调需要高质量的数据集，并不容易构建。此外，要实现接近GPT-3.5的性价比，还需要考虑硬件成本和利用率。   
+ 开源语言模型仍有工程实现上的挑战，需要进一步改进跨平台部署、批处理支持等。但未来微调将变得更简单，小型微调模型的应用将更广泛。   
+ 对不同的应用场景，是否值得微调开源模型而不是直接用GPT-3.5需要具体分析。翻译等任务使用GPT-3.5仍占优势。但对于特定领域的结构化查询，微调模型具有成本优势。   
+ 整体来说，微调对于大规模生产用例更有价值。对于小规模原型，引导GPT-3.5的简易性仍占优势。但随着工程实现的进步，微调的使用门槛将降低。  

## 5.4. 资讯 [在线游戏平台 Roblox 发布 名为 Roblox Assistant 的新型AI聊天机器人，让创作者只需输入提示即可构建虚拟世界](https://weibo.com/1402400261/Nj3JB1WWz)

