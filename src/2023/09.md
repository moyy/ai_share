- [AI: 2023.09](#ai-202309)
- [1. 工具](#1-工具)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.1. MindsDB 将 AI 模型连接到数据库](#21-mindsdb-将-ai-模型连接到数据库)
- [3. 模型](#3-模型)
  - [3.1. 用 投机采样（Speculative Sampling） 提升 推理效率](#31-用-投机采样speculative-sampling-提升-推理效率)
- [4. 技巧 / 教程](#4-技巧--教程)
- [5. 资讯 / 观点](#5-资讯--观点)

# AI: 2023.09

# 1. 工具

# 2. 项目 / 框架

## 2.1. [MindsDB 将 AI 模型连接到数据库](https://github.com/mindsdb/mindsdb)

MindsDB 的 AI 虚拟数据库使开发人员能够将任何 AI/ML 模型连接到任何数据源。这包括关系型和非关系型数据库、数据仓库和 SaaS 应用程序。 

+ 通过“增强的 SQL”抽象创建和管理 AI 模型（基于 LLM 的语义搜索和 QnA、时间序列预测、异常检测、分类、推荐等）。
+ 根据其支持的 130 多个数据源中包含的数据自动训练和微调 AI 模型。
+ 接入人工智能模型，使其在观察到新数据时自动运行，并将输出插入到我们的任何集成中。

# 3. 模型

## 3.1. [用 投机采样（Speculative Sampling） 提升 推理效率](https://mp.weixin.qq.com/s/VXiby6fUCWJEP3fsqHbTEw)

开源社区的一位开发者Georgi Gerganov发现，自己可以在M2 Ultra上运行全F16精度的34B Code Llama模型，而且推理速度超过了20 token/s。

毕竟，M2 Ultra的带宽有800GB/s。其他人通常需要4个高端GPU才能做到！

# 4. 技巧 / 教程

# 5. 资讯 / 观点

