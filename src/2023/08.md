- [AI: 2023.08](#ai-202308)
- [1. 工具](#1-工具)
  - [1.01. Pixellab.ai: 草图 / 线稿 变 像素插画](#101-pixellabai-草图--线稿-变-像素插画)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.01. LLaMA2-Accessory：LLM 开发的开源工具包](#201-llama2-accessoryllm-开发的开源工具包)
- [3. 模型](#3-模型)
  - [3.01. 把LLaMA-2的上下文扩展到32K](#301-把llama-2的上下文扩展到32k)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.01. 《深度学习需要的`矩阵微积分`》](#401-深度学习需要的矩阵微积分)
  - [4.02. llama2.c手把手代码解析](#402-llama2c手把手代码解析)
  - [4.03. 图解 transformer](#403-图解-transformer)
  - [4.03. 《结构化 Prompt》](#403-结构化-prompt)
- [5. 资讯 / 观点](#5-资讯--观点)

# AI: 2023.08

# 1. 工具

## 1.01. [Pixellab.ai: 草图 / 线稿 变 像素插画](https://weibo.com/1727858283/Ncrax4uAC)

# 2. 项目 / 框架

## 2.01. [LLaMA2-Accessory：LLM 开发的开源工具包](https://github.com/Alpha-VLLM/LLaMA2-Accessory)

这个repo主要继承自LLaMA-Adapter

LLaMA2-Accessory是一个开源工具包，用于大型语言模型 (LLM)和多模式 LLM的预训练、微调和部署。

+ 💡支持更多数据集和任务
+ 🎯使用RefinedWeb和StarCoder进行预训练。
+ 📚使用Alpaca、ShareGPT、LIMA、UltraChat和MOSS进行单模态微调。
+ 🌈使用图像文本对（ LAION、COYO等）、交错图像文本数据（MMC4和OBELISC）和视觉指令数据（LLaVA、Shrika、Bard）进行多模态微调
+ 🔧API 控制LLM（GPT4Tools和Gorilla）。
+ ⚡高效优化和部署
+ 🚝通过零初始注意和偏差范数调整进行参数高效的微调。
+ 💻完全分片数据并行 ( FSDP )、Flash Attention 2和QLoRA。
+ 🏋️‍♀️支持更多视觉编码器和LLM
+ 👁‍🗨视觉编码器：CLIP、Q-Former和ImageBind。
+ 🧩LLM：LLaMA 和 LLaMA2。

# 3. 模型

## 3.01. [把LLaMA-2的上下文扩展到32K](https://together.ai/blog/llama-2-7b-32k)

`Together.ai`发布了LLaMA-2-7B-32K模型。这个模型在LLaMA-2的基础上把上下文扩展到了32K。

# 4. 技巧 / 教程

## 4.01. [《深度学习需要的`矩阵微积分`》](https://explained.ai/matrix-calculus)

## 4.02. [llama2.c手把手代码解析](https://github.com/RahulSChand/llama2.c-for-dummies)

## 4.03. [图解 transformer](https://jalammar.github.io/illustrated-transformer/)

## 4.03. [《结构化 Prompt》](https://github.com/yzfly/LangGPT/blob/main/Docs/HowToWritestructuredPrompts.md)


# 5. 资讯 / 观点

