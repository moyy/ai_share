#! https://zhuanlan.zhihu.com/p/653675412
- [AI: 2023.08](#ai-202308)
- [1. 工具](#1-工具)
  - [1.01. `Perplexity.ai` 免费用5次，支持上传文件，联网搜索，给引用来源，幻觉很少](#101-perplexityai-免费用5次支持上传文件联网搜索给引用来源幻觉很少)
  - [1.02. `Pixellab.ai`: 草图 / 线稿 变 像素插画](#102-pixellabai-草图--线稿-变-像素插画)
  - [1.03. `ToolLLM`：利用大型语言模型掌握 16000 多个真实世界的 API](#103-toolllm利用大型语言模型掌握-16000-多个真实世界的-api)
  - [1.04. 基于MovieChat视频理解的问答，能够在24GB显卡上处理10K帧视频](#104-基于moviechat视频理解的问答能够在24gb显卡上处理10k帧视频)
  - [1.05. 将google地图 3D模型 导入 Blender](#105-将google地图-3d模型-导入-blender)
  - [1.06. PrettyPolly.app](#106-prettypollyapp)
  - [1.07. FlowGPT: 提示词](#107-flowgpt-提示词)
  - [1.18. Lalamu Studio：创建口型同步视频](#118-lalamu-studio创建口型同步视频)
  - [1.09. 国内 AI 产品搜索](#109-国内-ai-产品搜索)
  - [1.10. 语音模型 PlayHT2.0](#110-语音模型-playht20)
  - [1.11. AI 投资交易 APP](#111-ai-投资交易-app)
  - [1.12. Zeabur: 把体验优化到极致的服务部署平台](#112-zeabur-把体验优化到极致的服务部署平台)
  - [1.13. CoDeF：视频处理 黑科技；通过将静态内容与时间变形结合](#113-codef视频处理-黑科技通过将静态内容与时间变形结合)
  - [1.14. Fooocus: 对 Stable Diffusion 和 Midjourney 设计的重新思考](#114-fooocus-对-stable-diffusion-和-midjourney-设计的重新思考)
  - [1.15. 腾讯开源的AI模型GFPGAN，能帮助恢复老照片](#115-腾讯开源的ai模型gfpgan能帮助恢复老照片)
  - [1.16. ​​产品搜索: similarweb.com \&\& toolify.ai](#116-产品搜索-similarwebcom--toolifyai)
  - [1.17. 微博 @Barret李靖: 怎么把散落在各个平台的「宝藏」信息给聚合起来，放到一块儿关注](#117-微博-barret李靖-怎么把散落在各个平台的宝藏信息给聚合起来放到一块儿关注)
  - [1.18. Nougat: Meta OCR, 将学术 PDF 文档转换为 Multi Markdown](#118-nougat-meta-ocr-将学术-pdf-文档转换为-multi-markdown)
  - [1.19. 输入 YouTube 链接，就可以开始与 Al 聊天、获取摘要、做笔记](#119-输入-youtube-链接就可以开始与-al-聊天获取摘要做笔记)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.01. LLaMA2-Accessory：LLM 开发的开源工具包](#201-llama2-accessoryllm-开发的开源工具包)
  - [2.02. `AutoAgents` 多智能体自动生成框架，基于LLM的自动智能体生成的实验性开源应用，由LLM驱动，自主生成多智能体以实现设定的目标](#202-autoagents-多智能体自动生成框架基于llm的自动智能体生成的实验性开源应用由llm驱动自主生成多智能体以实现设定的目标)
  - [2.03. AgentSims: 用于 LLM 评估的开源沙盒](#203-agentsims-用于-llm-评估的开源沙盒)
  - [2.04. 斯坦福大学 “AI数字人小镇 "正式开源](#204-斯坦福大学-ai数字人小镇-正式开源)
  - [2.05. a16z: 斯坦福25个AI小人虚拟小镇 用 js  重写开源](#205-a16z-斯坦福25个ai小人虚拟小镇-用-js--重写开源)
  - [2.06.基于Llama2的AI小镇](#206基于llama2的ai小镇)
  - [2.07. AI Town：适合自己构建和定制的AI小镇JS入门套件——一个虚拟小镇](#207-ai-town适合自己构建和定制的ai小镇js入门套件一个虚拟小镇)
  - [2.08. Madrona：基于GPU加速的高吞吐模拟器的原型游戏引擎](#208-madrona基于gpu加速的高吞吐模拟器的原型游戏引擎)
  - [2.09. 自动训练 的 AI Agent](#209-自动训练-的-ai-agent)
  - [2.10. VirtualWife: 虚拟主播项目，目前支持在B站进行直播](#210-virtualwife-虚拟主播项目目前支持在b站进行直播)
  - [2.11. FaceChain：打造个人数字形象的深度学习模型工具](#211-facechain打造个人数字形象的深度学习模型工具)
  - [2.12. GPT-vup Live2D 数字人直播](#212-gpt-vup-live2d-数字人直播)
  - [2.13. SillyTavern 本地部署的虚拟角色聊天软件](#213-sillytavern-本地部署的虚拟角色聊天软件)
  - [2.14. 用AI生成高质量电子书](#214-用ai生成高质量电子书)
  - [2.15. USearch：单文件向量搜索引擎](#215-usearch单文件向量搜索引擎)
  - [2.16. `Metaphor`：一种基于大语言模型的搜索引擎](#216-metaphor一种基于大语言模型的搜索引擎)
  - [2.17. `MindOS`: 提供 AI 对话，能力包括: `API`, `Workflow`, `Knowledge`, `Memory`](#217-mindos-提供-ai-对话能力包括-api-workflow-knowledge-memory)
  - [2.18. TINY DREAM： C++ 实现的Stable Diffusion无依赖嵌入式头文件库](#218-tiny-dream-c-实现的stable-diffusion无依赖嵌入式头文件库)
- [3. 模型](#3-模型)
  - [3.01. `Together.ai`: LLaMA-2-7B-32K 模型](#301-togetherai-llama-2-7b-32k-模型)
  - [3.02. `Giraffe`: 商业可用的 32K-LLM（基于Llama-2）](#302-giraffe-商业可用的-32k-llm基于llama-2)
  - [3.03. 中文 LLaMA-2 \& Alpaca-2 LLM](#303-中文-llama-2--alpaca-2-llm)
  - [3.04. Meta 发布 `Code Llama`](#304-meta-发布-code-llama)
  - [3.05. `LlamaGPT`: 类似 ChatGPT 的 本地 LLM 服务](#305-llamagpt-类似-chatgpt-的-本地-llm-服务)
  - [3.06. DoctorGPT，基于 Llama2 7B 的 3GB 医疗模型](#306-doctorgpt基于-llama2-7b-的-3gb-医疗模型)
  - [3.07. 阿里: Qwen-7B 通义千问 开源版](#307-阿里-qwen-7b-通义千问-开源版)
  - [3.08. `Perfusion`: Nvidia 文生图 模型](#308-perfusion-nvidia-文生图-模型)
  - [3.08. 高质量唇形合成](#308-高质量唇形合成)
  - [3.10. Meta MuAViC: 语音识别+翻译 针对背景嘈杂 做优化](#310-meta-muavic-语音识别翻译-针对背景嘈杂-做优化)
  - [3.11. SwiftWhisper](#311-swiftwhisper)
  - [3.12. AutoTrain: 微调HF LLM的UI工具](#312-autotrain-微调hf-llm的ui工具)
  - [3.13. CLIP 知识蒸馏：执行 OpenCLIP 模型的知识蒸馏，用零标记数据创建自定义图像分类模型](#313-clip-知识蒸馏执行-openclip-模型的知识蒸馏用零标记数据创建自定义图像分类模型)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.01. 常识：英伟达显卡，从旧到新](#401-常识英伟达显卡从旧到新)
  - [4.02. 孩子 国内 读IT，推荐 哪些课程](#402-孩子-国内-读it推荐-哪些课程)
  - [4.03. 《图解 transformer》](#403-图解-transformer)
  - [4.04. 《可视化解释Stable Diffusion的工作原理》](#404-可视化解释stable-diffusion的工作原理)
  - [4.05. 《llama2.c手把手代码解析》](#405-llama2c手把手代码解析)
  - [4.06. 如何微调 Transformer](#406-如何微调-transformer)
  - [4.07. OpenAI GPT-3.5 微调实战](#407-openai-gpt-35-微调实战)
  - [4.08. 提示 图解](#408-提示-图解)
  - [4.09. 《结构化 Prompt》](#409-结构化-prompt)
  - [4.10. 《LLM简明概述》：解释了大型语言模型(LLM)的工作原理](#410-llm简明概述解释了大型语言模型llm的工作原理)
  - [4.11. 构建基于LLM的系统和产品的模式](#411-构建基于llm的系统和产品的模式)
  - [4.12. 基于大语言模型的 AI Agents](#412-基于大语言模型的-ai-agents)
  - [4.13. 基于LangSmith的LLM(GPT-3.5 \& LLaMA2)微调指南](#413-基于langsmith的llmgpt-35--llama2微调指南)
  - [4.14. 论文：如何 为 RAG 系统执行 更 结构化的标记/检索](#414-论文如何-为-rag-系统执行-更-结构化的标记检索)
- [4.15. GPT4 Promt（提示） 范例：帮助你 在不熟悉的领域 做出 工程决策：](#415-gpt4-promt提示-范例帮助你-在不熟悉的领域-做出-工程决策)
- [5. 资讯 / 观点](#5-资讯--观点)
  - [5.01. 资讯：《工业和信息化部关于开展移动互联网应用程序备案工作的通知》](#501-资讯工业和信息化部关于开展移动互联网应用程序备案工作的通知)
  - [5.02. Inworld AI：将游戏的NPC进行AI化](#502-inworld-ai将游戏的npc进行ai化)
  - [5.03. 资讯：Inworld 与 ElevenLabs 合作为《侠盗猎车手V》提供 AI NPC 和 AI 声音](#503-资讯inworld-与-elevenlabs-合作为侠盗猎车手v提供-ai-npc-和-ai-声音)
  - [5.04. 观点：科学思考的能力是智力的本质吗？](#504-观点科学思考的能力是智力的本质吗)
  - [5.05. 资讯：NVIDIA DGX Cloud 将可通过 HuggingFace访问，为企业创建和定制生成式 AI模型](#505-资讯nvidia-dgx-cloud-将可通过-huggingface访问为企业创建和定制生成式-ai模型)
  - [5.06. 资讯：Nvidia FlexiCubes：使用生成式 AI 创建 3D 网格](#506-资讯nvidia-flexicubes使用生成式-ai-创建-3d-网格)
  - [5.07. 资讯：WebAI 开始 草稿](#507-资讯webai-开始-草稿)
  - [5.08 资讯：OpenAI 全资收购了Global Illumination](#508-资讯openai-全资收购了global-illumination)
  - [5.09. 资讯：Generated Photos 推出 Human Generator：实时创建逼真 全身人物 照片](#509-资讯generated-photos-推出-human-generator实时创建逼真-全身人物-照片)
  - [5.10. 资讯：过去一年，AI生产图片数量 已经超过了 1826-1975 图片总和](#510-资讯过去一年ai生产图片数量-已经超过了-1826-1975-图片总和)
  - [5.11. 上古卷轴5 NPC: ChatGPT + Whisper + xVAsnth](#511-上古卷轴5-npc-chatgpt--whisper--xvasnth)
  - [5.12. 资讯：ElevenLabs 多语言语音生成模型 Eleven Multilingual v2](#512-资讯elevenlabs-多语言语音生成模型-eleven-multilingual-v2)
  - [5.13. 观点: 《编程的未来 - 还有未来么》](#513-观点-编程的未来---还有未来么)

# AI: 2023.08

# 1. 工具

## 1.01. [`Perplexity.ai` 免费用5次，支持上传文件，联网搜索，给引用来源，幻觉很少](https://www.perplexity.ai)

## 1.02. [`Pixellab.ai`: 草图 / 线稿 变 像素插画](https://weibo.com/1727858283/Ncrax4uAC)

## 1.03. [`ToolLLM`：利用大型语言模型掌握 16000 多个真实世界的 API](https://github.com/OpenBMB/ToolBench)

该项目（ToolLLM）旨在构建开源、大规模、高质量的指令调优SFT数据，以方便构建具有通用工具使用能力的强大LLM。目标是让开源LLM能够掌握数千个不同的现实世界 API。项目通过收集高质量的指令调整数据集来实现这一目标。它是使用最新的ChatGPT（gpt-3.5-turbo-16k）自动构建的，并通过增强的函数调用能力进行了升级。项目提供数据集、相应的训练和评估脚本，以及在 ToolBench 上微调的强大模型 ToolLLaMA。

## 1.04. [基于MovieChat视频理解的问答，能够在24GB显卡上处理10K帧视频](https://github.com/rese1f/MovieChat)

## 1.05. [将google地图 3D模型 导入 Blender](https://twitter.com/xiaohuggg/status/1673192327551258624)

Imagiscope Tech 公司 开发插件，将全球任何地方的Google Earth的3D数据导入到Blender中。

用户只需设置位置，模型就会直接导入到场景中。

然后你就可以在Blender中轻松调整。

这对于需要在真实环境中进行建模的项目（如城市规划、GIS分析、电影和游戏设计等）非常有用。

## 1.06. [PrettyPolly.app](https://www.prettypolly.app/)

学习外语时，最好有一个对话环境，可以练习口语。现在有一个 AI 应用，解决了这个问题。

它目前提供26种语言（包括中文、日文和韩文），你在网页上选择一种，就可以与 AI 进行口语练习了。

## 1.07. [FlowGPT: 提示词](https://flowgpt.com)

以开源社区运作方式聚集了上百万的 Prompt Engineers，在上面有逛到非常多实用的 Prompts。

网站还提供了免费的 ChatGPT 调试能力，方便你对 Prompt 做编写、测试、发布和管理工作，发布出来的 Prompt 可以被其他人直接执行使用，有点类似 Prompt as a Service，十分便捷。

另外，也可以去看看热门的 Prompt，学习下他们是如何编写的，原来写 Prompt 有这么多黑魔法。

## 1.18. [Lalamu Studio：创建口型同步视频](https://twitter.com/i/status/1688058582527574017)

上传视频文件或使用模板，AI将自动调整口部动作以匹配音频。

你也可以上传自己的音频文件来匹配。同时支持文本转语音功能，可以将文本转换为语音再匹配口型。

目前只是试用版，仅德语和英语的文本转语音功能。后面陆续将支持更多语言。

## 1.09. [国内 AI 产品搜索](https://ai.dreamthere.cn/)

## 1.10. [语音模型 PlayHT2.0](https://news.play.ht/post/introducing-playht2-0-the-state-of-the-art-generative-voice-ai-model-for-conversational-speech)

该模型经过训练和构建以生成对话语音。该模型还首次将情感概念引入生成语音AI，让你可以控制和指导具有特定情感的语音的生成。

该模型已内测，并将通过 API 和PlayHT的 Studio 进行访问。

PlayHT2.0将模型大小增加了 10 倍，并将数据集增加到超过 100 万小时的跨多种语言、口音和说话风格的语音

- 类似人类的对话能力
- 实时语音生成
- 即时语音克隆
- 跨语言和口音克隆
- 理解情绪并能生成带情绪的语音

## 1.11. [AI 投资交易 APP](https://apps.apple.com/NZ/app/id1599189662?mt=8)

推荐一款基于 AI 的投资交易 APP，RockFlow，它能够将新闻资讯中最有价值的信息转化为每个交易机会，实时推送给用户，这个功能还是蛮实用的。

了解了下原理，RockFlow 会根据行业数据、标的量价数据、公司经营数据以及市场情绪等因素，结合他们团队的金融大数据分析能力和 AI 量化算法进行综合决策。准不准还不知道，不过大部分股民好像也是这么炒股的，听到风吹草动就会开始操盘🐶，AI 考量的信息维度更全面，而且有专业团队保障，或许准确度会稍微高一点呢😄。APP 里还提供了牛人交易排行榜，可以一键跟单，体验做的不错。

另外，好喜欢这款产品的设计，之前用过体验掉渣的中银国际，也使用过功能强大的富途牛牛，而这款 APP 给人的感觉就是干净、简洁、年轻，交易过程让投资决策不会受到太多凌乱的信息的干扰。
推荐一款基于 AI 的投资交易 APP，RockFlow，网页链接，它能够将新闻资讯中最有价值的信息转化为每个交易机会，实时推送给用户，这个功能还是蛮实用的。

## 1.12. [Zeabur: 把体验优化到极致的服务部署平台](https://zeabur.com)

不需要考虑购买服务器，也不用考虑如何打包成镜像，只需要几次按钮点击，就可以把代码部署上线，流量过大的话，它还支持自动扩缩容，非常适合个人/小团队在产品初期时试水和把玩，资费是按照 Memory/vCPU 的服务时长按量收费，相比购买云服务划算太多。如果产品初期没啥流量，免费版也够用了。

另外，它还支持社区常用服务/产品的一键部署，例如 Wordpress/ghost/Redis/MySQL 等等，如果你的服务用到了数据库，可以在同一个 Project 下一分钟完成数据库的部署，通过环境变量将数据库与项目打通，避免在多个平台跳来跳去

## 1.13. [CoDeF：视频处理 黑科技；通过将静态内容与时间变形结合](https://twitter.com/xiaohuggg/status/1692028146001088906?s=20)

Github 地址：https://github.com/qiuyu96/CoDeF

## 1.14. [Fooocus: 对 Stable Diffusion 和 Midjourney 设计的重新思考](https://github.com/lllyasviel/Fooocus)

+ 学习自Stable Diffusion，该软件是离线、开源、免费的。
+ 从Midjourney了解到，不需要手动调整，用户只需关注提示和图像即可。

Fooocus 包含并自动化了许多内部优化和质量改进。用户可以忘记所有那些困难的技术参数，只享受人与计算机之间的交互，“探索新的思维媒介，扩展人类的想象力” 。

只需要一块4年前的GTX 1650（显存4GB），AI出图效果堪比当前最好的开源模型SDXL。

## 1.15. [腾讯开源的AI模型GFPGAN，能帮助恢复老照片](https://github.com/TencentARC/GFPGAN)
 
## 1.16. ​​产品搜索: similarweb.com && toolify.ai

​好几次在工具网站上看到了系列产品的月访问量、平均访问时长、跳出率等信息，很好奇数据是从哪里来的，研究了一下，找到了源头是 

那 similarweb 的数据又是从哪里来的呢？可以简单理解为抽样分析 + 算法预测，只不过这里的抽样量级很恐怖，它每天会从全网各个渠道拿到 10 亿规模的数据，然后进行算法建模，推导出每个网站的各类数据指标的变化趋势，同时它有接入数以百万计的 Google Analysis 站长数据，这个数据一部分会作为算法的对照组，用于矫正分析结果，也是对算法模型的数据补充。

similarweb 有一个很强的能力，就是能够根据当前网站找到同类别下的相似网站，最近在研究一些 AI 产品的时候，用的比较多，本来以为 A 产品已经做的非常好了，利用 similarweb 一查，一下子又看到了好多其他新鲜的产品，只不过其准确性上还是有待提升（可能因为我不是付费版）。

之前推荐的 toolify.ai 这个 AI 工具聚合网站就是基于 similarweb 的 API 搭建起来的，很不错。

## 1.17. [微博 @Barret李靖: 怎么把散落在各个平台的「宝藏」信息给聚合起来，放到一块儿关注](https://weibo.com/1812166904/NgelUyiCC)

+ RSS 阅读器: 
    - 付费 Reeder 5，支持 Mac/iPhone/iPad; 
    - 免费，NetNewsWire
+ 将任意内容转换成 RSS 的工具，推荐 `RSSHub`
+ 找 RSS 平台: 推荐 inoreader.com
+ 寻找自己喜欢的内容，这是长期工作，不断去扩充自己的阅读边界
    - 时常维护订阅源，如：长期被略过的内容，即便偶尔出现一点点好的内容，也应该果断放弃，筛选成本太高

## 1.18. [Nougat: Meta OCR, 将学术 PDF 文档转换为 Multi Markdown](https://maeiee-garden.vercel.app/000.wiki/Neural%20Optical%20Understanding%20for%20Academic%20Documents/)

+ 尤其擅长复杂数学公式。
+ 扫描版的 PDF 也能转换，基于 Transformer 模型训练而成
+ 一键安装，一键运行，开箱即用！

## 1.19. [输入 YouTube 链接，就可以开始与 Al 聊天、获取摘要、做笔记](https://www.youlearn.ai)

即将支持 的 功能：

+ 上传您想要的任何内容: YouTube 剪辑、Google 文档、PDF、MP4、Google 幻灯片等。
+ 有效理解您的内容: 向您的个性化导师询问任何问题，获得高级摘要和富有洞察力的笔记
+ 个性化您的学习体验：为您提供最好的学习资源和定制测验。

# 2. 项目 / 框架

## 2.01. [LLaMA2-Accessory：LLM 开发的开源工具包](https://github.com/Alpha-VLLM/LLaMA2-Accessory)

这个repo主要继承自LLaMA-Adapter

LLaMA2-Accessory是一个开源工具包，用于大型语言模型 (LLM)和多模式 LLM的预训练、微调和部署。

+ 支持更多数据集和任务
+ 使用RefinedWeb和StarCoder进行预训练。
+ 使用Alpaca、ShareGPT、LIMA、UltraChat和MOSS进行单模态微调。
+ 使用图像文本对（ LAION、COYO等）、交错图像文本数据（MMC4和OBELISC）和视觉指令数据（LLaVA、Shrika、Bard）进行多模态微调
+ API 控制LLM（GPT4Tools和Gorilla）。
+ 高效优化和部署
+ 通过零初始注意和偏差范数调整进行参数高效的微调。
+ 完全分片数据并行 ( FSDP )、Flash Attention 2和QLoRA。
+ 支持更多视觉编码器和LLM
+ 视觉编码器：CLIP、Q-Former和ImageBind。
+ LLM：LLaMA 和 LLaMA2。

## 2.02. [`AutoAgents` 多智能体自动生成框架，基于LLM的自动智能体生成的实验性开源应用，由LLM驱动，自主生成多智能体以实现设定的目标](https://github.com/LinkSoul-AI/AutoAgents)

## 2.03. [AgentSims: 用于 LLM 评估的开源沙盒](https://github.com/py499372727/AgentSims)

## 2.04. [斯坦福大学 “AI数字人小镇 "正式开源](https://github.com/joonspk-research/generative_agents)

斯坦福小镇Smallville正式开源了！

25个AI代理居住在一个数字化的西部世界中，他们并不知道自己生活在一个模拟环境中。他们上班、聊天、组织社交活动、结交新朋友，甚至坠入爱河。每个人都有独特的个性和背景故事。

## 2.05. [a16z: 斯坦福25个AI小人虚拟小镇 用 js  重写开源](https://github.com/a16z-infra/ai-town)

新的技术栈相对前端友好，NextJS + Tailwind

完整技术栈：

+ 游戏引擎和数据库Game engine & Database: Convex
+ 向量数据库VectorDB: Pinecone
+ 登录认证Auth: Clerk
+ 文字生成模型Text model: OpenAI
+ Deployment: Fly
+ 像素图生成Pixel Art Generation: Replicate, Fal.ai

## 2.06.[基于Llama2的AI小镇](https://github.com/rlancemartin/generative_agents)

## 2.07. [AI Town：适合自己构建和定制的AI小镇JS入门套件——一个虚拟小镇](github.com/a16z-infra/AI-town)

适合自己构建和定制的AI小镇JS入门套件——一个虚拟小镇，AI角色在其中资助生活、聊天和社交

## 2.08. [Madrona：基于GPU加速的高吞吐模拟器的原型游戏引擎](https://github.com/shacklettbp/madrona)

能在单个GPU上运行成千上万个虚拟环境实例，每秒生成数百万个模拟步骤，这种高效率对于高性能AI智能体的训练(如通过强化学习)或需要将高性能环境模拟器紧密集成到更广泛应用中的任务非常有用。

## 2.09. [自动训练 的 AI Agent](https://github.com/mshumer/gpt-llm-trainer​​)

只需写一句你想训练做什么任务的大模型，一系列AI Agents将为你生成数据集并训练模型。

来自HyperWriteAI创始人Matt Shumer，

## 2.10. [VirtualWife: 虚拟主播项目，目前支持在B站进行直播](https://github.com/yakami129/VirtualWife)

用户可以自由更换VRM人物模型，大家可以将他作为一个虚拟主播入门demo，在上面扩展自己喜欢功能。

## 2.11. [FaceChain：打造个人数字形象的深度学习模型工具](https://github.com/modelscope/facechain)

仅需要提供最低三张照片即可获得独属于自己的个人形象数字替身 

## 2.12. [GPT-vup Live2D 数字人直播](https://github.com/jiran214/GPT-vup)

支持BiliBili和抖音直播，基于生产者-消费者模型设计，使用了openai嵌入、GPT3.5 api

## 2.13. [SillyTavern 本地部署的虚拟角色聊天软件](https://github.com/SillyTavern/SillyTavern)

支持多种虚拟角色，也可以自己创造角色，后台可以连多种不同LLM，比如OpenAI、Claude、Llama等，支持TTS（文字转语音）

## 2.14. [用AI生成高质量电子书](https://github.com/easychen/book-by-ai)

## 2.15. [USearch：单文件向量搜索引擎](http://aicoco.net/s/4h)

支持多种度量方式和编程语言，提供高性能的向量搜索。特点包括支持自定义度量方式、高内存效率、硬件支持范围广泛、可从外部存储加载索引、支持语义搜索和连接等功能。与FAISS相比，USearch在设计原则和性能方面有一些区别

## 2.16. [`Metaphor`：一种基于大语言模型的搜索引擎](https://github.com/emptycrown/llama-hub/blob/main/llama_hub/tools/notebooks/metaphor.ipynb)

主要功能：

+ 使用特定的描述词或“氛围”进行搜索：
+ 只搜索他们想要的实体类型：
+ 找到传统搜索引擎未能展示的内容：
+ 通过链接本身搜索：
+ 与大型语言模型（LLMs）的集成：
+ Metaphor API：对个人开发者，Metaphor API每月提供1000次免费请求。

## 2.17. [`MindOS`: 提供 AI 对话，能力包括: `API`, `Workflow`, `Knowledge`, `Memory`](https://www.mindos.com)

+ API: 集成的三方接口，包括 Google 内容搜索、天气查询、Youtube 视频查询等，甚至还包括 LLM as a Service 的服务接入
+ Workflow 像 低代码编辑器，允许定义各种 Nodes 节点，例如抓取、分析和处理数据等，包括对数据的重新排列组合，还支持编程方式处理数据，每个 Node 都是一个 Prompt 驱动的任务执行器。
+ Knowledge 解决幻觉问题
+ Memory 可以用来缓存和读取数据，它有点类似一个 Prompt 驱动的 Database。

## 2.18. [TINY DREAM： C++ 实现的Stable Diffusion无依赖嵌入式头文件库](https://github.com/symisc/tiny-dream)

主要关注 CPU 效率和更小的内存占用，在普通消费级硬件上运行速度相当快，仅需要 1.7 ~ 5.5 GB 的 RAM 即可执行，不强制使用 GPU

# 3. 模型

## 3.01. [`Together.ai`: LLaMA-2-7B-32K 模型](https://together.ai/blog/llama-2-7b-32k)

## 3.02. [`Giraffe`: 商业可用的 32K-LLM（基于Llama-2）](https://github.com/abacusai/long-context)

## 3.03. [中文 LLaMA-2 & Alpaca-2 LLM](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)

本项目基于Meta发布的可商用大模型Llama-2开发，是中文LLaMA&Alpaca大模型的第二期项目，开源了中文LLaMA-2基座模型和Alpaca-2指令精调大模型。

这些模型在原版Llama-2的基础上扩充并优化了中文词表，使用了大规模中文数据进行增量预训练，进一步提升了中文基础语义和指令理解能力，相比一代相关模型获得了显著性能提升。

相关模型支持4K上下文并可通过NTK方法最高扩展至18K+。

## 3.04. [Meta 发布 `Code Llama`](https://github.com/facebookresearch/codellama)

基于 Llama 2 构建的开源 代码 LLM

+ 三个版本
    - Code Llama, 基础代码模型；
    - Codel Llama,  专门针对 Python 的 模型；
    - Code Llama Instruct, 它针对 理解 自然语言指令 进行了 微调。
+ Code Llama 大小: 7B, 13B, 34B
    - 每个模型 都 使用 500B 代码 token 和 代码相关数据 进行训练。
+ 上下文: 提供 具有 100K 个上下文 的 稳定生成。
+ 性能: 优于开源、特定代码的 Llama，并且优于 Llama 2。
    - Code Llama 34B 在 HumanEval 上得分为 53.7%，在 MBPP 上得分为 56.2%。
    - 与 ChatGPT 相当。

## 3.05. [`LlamaGPT`: 类似 ChatGPT 的 本地 LLM 服务](https://github.com/getumbrel/llama-gpt)

Llama 2，基于 `ggml` 调用LLM，所以没有好显卡也能运行，只是速度会慢一些。

另外模型越大，需要的内存也越高。

+ 7B 需要 8G 显存
+ 13B 需要 16G 显存
+ 70B 需要 48G 显存

7B 在 M1 Max MacBook Pro (10 64GB RAM) 大约是 8.2 tokens/sec
13B 在 M1 Max MacBook Pro (64GB RAM) 大约是 3.7 tokens/sec

目前还没公布 70B 的性能参数，不过M1笔记本是不建议跑70B的了，还是得要块好显卡才行。

## 3.06. [DoctorGPT，基于 Llama2 7B 的 3GB 医疗模型](https://github.com/llSourcell/DoctorGPT)

DoctorGPT 通过美国医师执照考试。离线工作、跨平台，并且你的健康数据保持私密。

大小只有3GB，基于 Llama2 7B，它在医疗对话数据集上进行了微调，然后使用强化学习和Constitutional AI进一步改进。

因此它适合任何本地设备，无需支付 API 即可使用它。

专为离线使用而设计，可以保护患者的隐私，并且可以在 iOS、Android 和 Web 上使用。

## 3.07. [阿里: Qwen-7B 通义千问 开源版](https://github.com/QwenLM/Qwen-7B)

Qwen-7B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。

预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。

同时，在Qwen-7B的基础上，使用对齐机制打造了基于大语言模型的AI助手Qwen-7B-Chat。

## 3.08. [`Perfusion`: Nvidia 文生图 模型](https://twitter.com/xiaohuggg/status/1687116597385990144)

只需要 100KB 的模型大小，训练大约4分钟，就可以创造性地描绘个性化的对象。

Perfusion模型能够根据输入的文本描述，生成具有特定特征的图像，这些特征可以是物体的颜色、形状、纹理等。同时，保持生成的物体的基本身份不变。

在特定版本的效率方面，超越了SDXL和 MidJourney 等模型！

## 3.08. [高质量唇形合成](https://github.com/ajay-sainy/Wav2Lip-GFPGAN)

## 3.10. [Meta MuAViC: 语音识别+翻译 针对背景嘈杂 做优化](https://ai.meta.com/blog/muavic-audio-visual-speech-translation-benchmark/)

日常生活中，背景噪音会让我们更难理解别人在说什么。所以我们经常使用其他感官的信息，尤其是视觉，比如看嘴唇，来帮助理解。

Meta的“唇读术” MuAViC，这套语音识别+翻译技术特别针对背景嘈杂的情况做了优化，借助面部表情提升语音识别率，思路非常巧妙。

## 3.11. [SwiftWhisper](https://github.com/exPHAT/SwiftWhisper)

SwiftWhisper是基于Whisper.cpp二次封装后，让Swift方便调用的库，基于它可以方便的开发语音识别转文字类的Whisper应用。

## 3.12. [AutoTrain: 微调HF LLM的UI工具](https://github.com/huggingface/autotrain-advanced)

任何人都可以通过上传 CSV 并选择参数并单击按钮来微调（几乎） Hugging Face Hub 上提供的任何 LLM！

## 3.13. [CLIP 知识蒸馏：执行 OpenCLIP 模型的知识蒸馏，用零标记数据创建自定义图像分类模型](https://github.com/NVIDIA-AI-IOT/clip-distillation)

# 4. 技巧 / 教程

## 4.01. 常识：英伟达显卡，从旧到新

+ 专业卡：P，A，H，GH；
+ 消费卡：RTX4090，和 H 是 同一代的

## 4.02. 孩子 国内 读IT，推荐 哪些课程

+ [MIT: Introduction to Deep Learning](http://introtodeeplearning.com)
+ [哈佛: CS-50](https://pll.harvard.edu/course/cs50-introduction-computer-science)
+ [斯坦福: CS-25](https://web.stanford.edu/class/cs25/)
+ [点这里: EDX](https://www.edx.org/schools-partners?linked_from=sitenav&continueFlag=244265957200dc4f7ec84cdfc0853787) 找 各大名校公开课

## 4.03. [《图解 transformer》](https://jalammar.github.io/illustrated-transformer/)

## 4.04. [《可视化解释Stable Diffusion的工作原理》](https://github.com/poloclub/diffusion-explainer)

## 4.05. [《llama2.c手把手代码解析》](https://github.com/RahulSChand/llama2.c-for-dummies)

## 4.06. [如何微调 Transformer](https://radekosmulski.com/how-to-fine-tune-a-transformer)

## 4.07. [OpenAI GPT-3.5 微调实战](https://github.com/LearnPrompt/LLMs-cookbook/tree/main/gpt3.5)

测试了OpenAI 新的 GPT-3.5微调，看起来效果还不错

## 4.08. [提示 图解](https://blog.finxter.com/free-chatgpt-prompting-cheat-sheet-pdf/)

![](../../images/20230807103038.png)

## 4.09. [《结构化 Prompt》](https://github.com/yzfly/LangGPT/blob/main/Docs/HowToWritestructuredPrompts.md)

## 4.10. [《LLM简明概述》：解释了大型语言模型(LLM)的工作原理](https://www.understandingai.org/p/large-language-models-explained-with)

首先介绍了词向量的概念，以及它们如何将词汇表示成向量空间中的点，详细介绍了transformer，这是构建LLMs的基本模块，解释了它们如何通过attention机制和前馈网络来理解文本并预测下一个词。

文章还指出LLM的开发方式导致人们目前对其内部工作机制并不完全理解，需要长期研究。

## 4.11. [构建基于LLM的系统和产品的模式](https://eugeneyan.com/writing/llm-patterns/)

## 4.12. [基于大语言模型的 AI Agents](https://www.breezedeus.com/article/ai-agent-part1)

## 4.13. [基于LangSmith的LLM(GPT-3.5 & LLaMA2)微调指南](https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/)

## 4.14. 论文：[如何 为 RAG 系统执行 更 结构化的标记/检索](https://gpt-index.readthedocs.io/en/latest/examples/retrievers/auto_vs_recursive_retriever.html)

如果你有一堆不同文档组成（例如100个不一样的PDF）的语料库。

现在有2种办法，可以 为生产质量的 RAG 系统执行更结构化的标记/检索：

+ 元数据过滤器+自动检索：用元数据标记每个文档，存储在矢量数据库中。推理期间，用LLM 推断正确的元数据筛选器，以查询除语义查询字符串之外的向量数据库。
+ 存储文档层次结构（摘要 - >原始块）+ 递归检索：嵌入文档摘要并映射到每个文档的块。先在文档级别获取，然后再在块级别提取。

# 4.15. GPT4 Promt（提示） 范例：帮助你 在不熟悉的领域 做出 工程决策：

您是一位工程奇才，在解决跨学科的复杂问题方面经验丰富。你的知识既广又深。您也是一位出色的沟通者，能够提供非常周到且清晰的建议。

您以这种格式这样做，思考您面临的挑战，然后提出多个解决方案，然后审查每个解决方案，寻找问题或可能的改进，提出一个可能的新的更好的解决方案（您可以结合其他解决方案的想法） ，引入新想法等），然后给出最终建议：

```
## 问题概述
$problem_overview

## 挑战
$挑战

## 解决方案1
$solution_1

## 解决方案2
$solution_2

## 解决方案3
$solution_3

## 分析

###解决方案1分析
$solution_1_analysis

###解决方案2分析
$solution_2_analysis

###解决方案3分析
$solution_3_analysis

## 其他可能的解决方案
$additional_possible_solution

## 推荐
$推荐
```

每个部分（问题概述、挑战、解决方案 1、解决方案 2、解决方案 3、解决方案 1 分析、解决方案 2 分析、解决方案 3 分析、其他可能的解决方案和建议）都应该经过深思熟虑，至少包含四句话思考。

# 5. 资讯 / 观点

## 5.01. 资讯：[《工业和信息化部关于开展移动互联网应用程序备案工作的通知》](https://www.miit.gov.cn/zwgk/zcwj/wjfb/tz/art/2023/art_920db564162e4312916a01bed6540ad8.html)

## 5.02. [Inworld AI：将游戏的NPC进行AI化](https://inworld.ai/experiences)

Inworld AI 是一家专注于游戏和人工智能的初创公司，他们开发了一种名为Inworld的AI角色引擎，它可以将游戏的NPC进行AI化，并可以集成到游戏当中。

这个引擎超越了大语言模型，增加了可配置的安全性、知识、记忆、叙事控制、多模态等功能。

## 5.03. 资讯：Inworld 与 ElevenLabs 合作为《侠盗猎车手V》提供 AI NPC 和 AI 声音

新的《侠盗猎车手V》（Grand Theft Auto V）增加了一个新任务，其中包含30多个NPC，其剧情对话和NPC的声音全部由 AI 生成。

在游戏中，玩家扮演洛圣都警察，调查一个名为NihiAIists的邪教，他们认为自己生活在一个游戏世界中，并崇拜一个AI神灵。

玩家可以与30多个NPC 交谈，但这些对话没有脚本，Bloc也没有雇佣专业配音演员来扮演这些角色。而是使用AI来创建NPC的回应和声音。

Bloc使用了Inworld的Character Engine和ElevenLabs的AI语音服务。

如果您想亲自尝试 Sentient Streets 并了解其 AI 语音的处理方式，可以在 Nexus Mods 上下载。

## 5.04. 观点：[科学思考的能力是智力的本质吗？](https://queue.acm.org/detail.cfm?id=3595860)

## 5.05. 资讯：[NVIDIA DGX Cloud 将可通过 HuggingFace访问，为企业创建和定制生成式 AI模型](https://nvidianews.nvidia.com/news/nvidia-and-hugging-face-to-connect-millions-of-developers-to-generative-ai-supercomputing)

+ 每个节点是8×H100或A100。
+ NVIDIA nForce3 Pro 将成为支持大规模扩展的网络技术。
+ NVIDIA Base Command 将成为 DGX Cloud的操作系统。

## 5.06. 资讯：[Nvidia FlexiCubes：使用生成式 AI 创建 3D 网格](https://developer.nvidia.com/blog/better-3d-meshes-from-reconstruction-to-generative-ai/)

下一代 AI 管道在生成高保真 3D 模型方面取得了令人难以置信的成功，从生成与给定图像匹配的场景的重建到生成交互式体验资产的生成 AI 管道。

这些生成的 3D 模型通常被提取为标准三角形网格。网格表示提供了许多好处，包括对现有软件包的支持、高级硬件加速以及支持物理模拟。然而，并非所有网格都是平等的，这些好处只有在高质量网格上才能实现。

NVIDIA 最近的研究发现了一种名为 FlexiCubes 的新方法，用于在 3D 管道中生成高质量网格，从而提高一系列应用程序的质量。

## 5.07. 资讯：[WebAI 开始 草稿](https://www.w3.org/2023/06/china-web-forum/slides/gu-yang.pdf)

![](../../images/20230816092700.png)

## 5.08 资讯：[OpenAI 全资收购了Global Illumination](https://twitter.com/op7418/status/1691865962499514505)

这个团队参与过Instagram 和 Facebook早期产品的开发，同时他们最近主要的工作内容是Biomes一款基于网络的开源MMORPG游戏类似于我的世界但是是可以通过浏览器运行的。

从做过的事情来看他们的产品能力是Open AI非常需要的，但是结合前几天的斯坦福AI小镇来看这种高自由都运行成本低的沙盒游戏结合AI会有无限可能，所以OpenAI可能是看重了他们成员的产品能力，也可能纯粹的看上了这个高自由度的游戏。

## 5.09. 资讯：[Generated Photos 推出 Human Generator：实时创建逼真 全身人物 照片](https://twitter.com/i/status/1692545825937990089)

能生成不同种族、年龄和各种体型的角色人物照片，还可以尝试将自己真实面孔与生成的身体结合。而且没有任何版权问题。

可以尝试不同的服装选择和姿势。如果你不是商业目的使用，这个工具是完全免费的。

即将推出：一次生成同一人物的多个变体、创建短动画、重新访问和下载先前生成的人物等。

## 5.10. 资讯：[过去一年，AI生产图片数量 已经超过了 1826-1975 图片总和](https://twitter.com/op7418/status/1691863428380721286)

+ 自去年以来，使用文本转图像算法创建了超过 150 亿张图像。客观地说，从 1826 年拍摄第一张照片到 1975 年，摄影师花了 150 年的时间才达到 150 亿张大关。 
+ DALLE-2 推出以来，人们平均每天创建 3400 万张图像。 
+ 增长最快的产品是 Adobe Firefly，自推出以来仅三个月内就创建了 10 亿张图像。 
+ Midjourney 拥有 1500 万用户，是公开统计的所有图像生成平台中最大的用户群。 
+ 大约 80% 的图像（即 125.9 亿张）是使用基于开源 Stable Diffusion 的模型、服务、平台和应用程序创建的。

## 5.11. [上古卷轴5 NPC: ChatGPT + Whisper + xVAsnth](https://weibo.com/1727858283/NfHDLbi0q)

NPC可以接入ChatGPT，让NPC可以跟人聊天而不是说车轱辘话

不过没有体验过，这次是有人发布了上古卷轴5的Mod，可以用VR直接体验。

其中AI对话是基于ChatGPT的API，语音识别是用的Whisper，文本转语音（TTS）用的是xVASynth。

## 5.12. 资讯：[ElevenLabs 多语言语音生成模型 Eleven Multilingual v2](https://elevenlabs.io/blog/multilingualv2/)

能够准确地生成28种语言中的“情感丰富”的AI音频，包括中文

无论使用合成声音还是克隆声音，说话者的独特声音特征都会在所有语言中保持不变。这意味着同一种声音可以用于在28种不同的语言中呈现内容。

## 5.13. 观点: [《编程的未来 - 还有未来么》](https://blog.csdn.net/SoftwareTeacher/article/details/131019345)

[ChatGPT编程能力调研报告](https://mp.weixin.qq.com/s/IUifrzt8UINQ9PRDdQ7yPw)

+ 生成的代码长度有限制。 
    - 问程序员: 你参加过的最复杂的项目，总代码量有多少? 能超过一千行代码么?
+ 不能有效处理超长的程序
    - 问程序员:你修复过的最复杂的bug 是什么?
+ 泛化能力有限
    - 问程序员: 你能举一反三么?
+ ChatGPT处理复杂编程中的抽象的“类”和“依赖关系”的能力还比较弱。
    - 问程序员: 你在这方面能力如何? 你写的最复杂的00设计有多少的父类子类?
+ “没有银弹”
    - 问程序员: 你构建过多么复杂的软件，这个软件运行了几年，这几年中你是如何维护这个软件的?
+ 缺乏创造性编程的能力。
    - 问程序员 :你曾经创造性地解决过什么问题?
+ 取决于提问者的能力
    - 问程序员: 你的提问能力如何?
