- [AI: 2023.08](#ai-202308)
- [1. 工具](#1-工具)
  - [1.01. Pixellab.ai: 草图 / 线稿 变 像素插画](#101-pixellabai-草图--线稿-变-像素插画)
  - [1.02. ToolLLM：利用大型语言模型掌握 16000 多个真实世界的 API](#102-toolllm利用大型语言模型掌握-16000-多个真实世界的-api)
  - [1.03. 基于MovieChat视频理解的问答，能够在24GB显卡上处理10K帧视频](#103-基于moviechat视频理解的问答能够在24gb显卡上处理10k帧视频)
  - [1.04. 将google地图 3D模型 导入 Blender](#104-将google地图-3d模型-导入-blender)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.01. LLaMA2-Accessory：LLM 开发的开源工具包](#201-llama2-accessoryllm-开发的开源工具包)
  - [2.02. USearch：单文件向量搜索引擎](#202-usearch单文件向量搜索引擎)
- [3. 模型](#3-模型)
  - [3.01. 把LLaMA-2的上下文扩展到32K](#301-把llama-2的上下文扩展到32k)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.01. 《深度学习需要的`矩阵微积分`》](#401-深度学习需要的矩阵微积分)
  - [4.02. 《llama2.c手把手代码解析》](#402-llama2c手把手代码解析)
  - [4.03. 《图解 transformer》](#403-图解-transformer)
  - [4.04. 《可视化解释Stable Diffusion的工作原理》](#404-可视化解释stable-diffusion的工作原理)
  - [4.05. 《结构化 Prompt》](#405-结构化-prompt)
  - [4.06. 《LLM简明概述》：解释了大型语言模型(LLM)的工作原理](#406-llm简明概述解释了大型语言模型llm的工作原理)
- [5. 资讯 / 观点](#5-资讯--观点)

# AI: 2023.08

# 1. 工具

## 1.01. [Pixellab.ai: 草图 / 线稿 变 像素插画](https://weibo.com/1727858283/Ncrax4uAC)

## 1.02. [ToolLLM：利用大型语言模型掌握 16000 多个真实世界的 API](https://github.com/OpenBMB/ToolBench)

该项目（ToolLLM）旨在构建开源、大规模、高质量的指令调优SFT数据，以方便构建具有通用工具使用能力的强大LLM。目标是让开源LLM能够掌握数千个不同的现实世界 API。项目通过收集高质量的指令调整数据集来实现这一目标。它是使用最新的ChatGPT（gpt-3.5-turbo-16k）自动构建的，并通过增强的函数调用能力进行了升级。项目提供数据集、相应的训练和评估脚本，以及在 ToolBench 上微调的强大模型 ToolLLaMA。

## 1.03. [基于MovieChat视频理解的问答，能够在24GB显卡上处理10K帧视频](https://github.com/rese1f/MovieChat)

## 1.04. [将google地图 3D模型 导入 Blender](https://twitter.com/xiaohuggg/status/1673192327551258624)

Imagiscope Tech 公司 开发插件，将全球任何地方的Google Earth的3D数据导入到Blender中。

用户只需设置位置，模型就会直接导入到场景中。

然后你就可以在Blender中轻松调整。

这对于需要在真实环境中进行建模的项目（如城市规划、GIS分析、电影和游戏设计等）非常有用。

# 2. 项目 / 框架

## 2.01. [LLaMA2-Accessory：LLM 开发的开源工具包](https://github.com/Alpha-VLLM/LLaMA2-Accessory)

这个repo主要继承自LLaMA-Adapter

LLaMA2-Accessory是一个开源工具包，用于大型语言模型 (LLM)和多模式 LLM的预训练、微调和部署。

+ 💡支持更多数据集和任务
+ 🎯使用RefinedWeb和StarCoder进行预训练。
+ 📚使用Alpaca、ShareGPT、LIMA、UltraChat和MOSS进行单模态微调。
+ 🌈使用图像文本对（ LAION、COYO等）、交错图像文本数据（MMC4和OBELISC）和视觉指令数据（LLaVA、Shrika、Bard）进行多模态微调
+ 🔧API 控制LLM（GPT4Tools和Gorilla）。
+ ⚡高效优化和部署
+ 🚝通过零初始注意和偏差范数调整进行参数高效的微调。
+ 💻完全分片数据并行 ( FSDP )、Flash Attention 2和QLoRA。
+ 🏋️‍♀️支持更多视觉编码器和LLM
+ 👁‍🗨视觉编码器：CLIP、Q-Former和ImageBind。
+ 🧩LLM：LLaMA 和 LLaMA2。

## 2.02. [USearch：单文件向量搜索引擎](http://aicoco.net/s/4h)

支持多种度量方式和编程语言，提供高性能的向量搜索。特点包括支持自定义度量方式、高内存效率、硬件支持范围广泛、可从外部存储加载索引、支持语义搜索和连接等功能。与FAISS相比，USearch在设计原则和性能方面有一些区别


# 3. 模型

## 3.01. [把LLaMA-2的上下文扩展到32K](https://together.ai/blog/llama-2-7b-32k)

`Together.ai`发布了LLaMA-2-7B-32K模型。这个模型在LLaMA-2的基础上把上下文扩展到了32K。

# 4. 技巧 / 教程

## 4.01. [《深度学习需要的`矩阵微积分`》](https://explained.ai/matrix-calculus)

## 4.02. [《llama2.c手把手代码解析》](https://github.com/RahulSChand/llama2.c-for-dummies)

## 4.03. [《图解 transformer》](https://jalammar.github.io/illustrated-transformer/)

## 4.04. [《可视化解释Stable Diffusion的工作原理》](https://github.com/poloclub/diffusion-explainer)
## 4.05. [《结构化 Prompt》](https://github.com/yzfly/LangGPT/blob/main/Docs/HowToWritestructuredPrompts.md)

## 4.06. [《LLM简明概述》：解释了大型语言模型(LLM)的工作原理](https://www.understandingai.org/p/large-language-models-explained-with)

首先介绍了词向量的概念，以及它们如何将词汇表示成向量空间中的点，详细介绍了transformer，这是构建LLMs的基本模块，解释了它们如何通过attention机制和前馈网络来理解文本并预测下一个词。

文章还指出LLM的开发方式导致人们目前对其内部工作机制并不完全理解，需要长期研究

# 5. 资讯 / 观点

