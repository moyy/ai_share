- [AI: 2023.08](#ai-202308)
- [1. 工具](#1-工具)
  - [1.01. Pixellab.ai: 草图 / 线稿 变 像素插画](#101-pixellabai-草图--线稿-变-像素插画)
  - [1.02. ToolLLM：利用大型语言模型掌握 16000 多个真实世界的 API](#102-toolllm利用大型语言模型掌握-16000-多个真实世界的-api)
  - [1.03. 基于MovieChat视频理解的问答，能够在24GB显卡上处理10K帧视频](#103-基于moviechat视频理解的问答能够在24gb显卡上处理10k帧视频)
  - [1.04. 将google地图 3D模型 导入 Blender](#104-将google地图-3d模型-导入-blender)
  - [1.05. Meta开源了 AudioCraft：文本 -- 声音](#105-meta开源了-audiocraft文本----声音)
  - [1.07. PrettyPolly.app](#107-prettypollyapp)
- [2. 项目 / 框架](#2-项目--框架)
  - [2.01. LLaMA2-Accessory：LLM 开发的开源工具包](#201-llama2-accessoryllm-开发的开源工具包)
  - [2.02. USearch：单文件向量搜索引擎](#202-usearch单文件向量搜索引擎)
- [3. 模型](#3-模型)
  - [3.01. 把LLaMA-2的上下文扩展到32K](#301-把llama-2的上下文扩展到32k)
  - [3.02. 阿里: Qwen-7B 通义千问 开源版](#302-阿里-qwen-7b-通义千问-开源版)
  - [3.03. 中文LLaMA-2 \& Alpaca-2 LLM](#303-中文llama-2--alpaca-2-llm)
- [4. 技巧 / 教程](#4-技巧--教程)
  - [4.01. 《深度学习需要的`矩阵微积分`》](#401-深度学习需要的矩阵微积分)
  - [4.02. 《llama2.c手把手代码解析》](#402-llama2c手把手代码解析)
  - [4.03. 《图解 transformer》](#403-图解-transformer)
  - [4.04. 《可视化解释Stable Diffusion的工作原理》](#404-可视化解释stable-diffusion的工作原理)
  - [4.05. 《结构化 Prompt》](#405-结构化-prompt)
  - [4.06. 《LLM简明概述》：解释了大型语言模型(LLM)的工作原理](#406-llm简明概述解释了大型语言模型llm的工作原理)
- [5. 资讯 / 观点](#5-资讯--观点)

# AI: 2023.08

# 1. 工具

## 1.01. [Pixellab.ai: 草图 / 线稿 变 像素插画](https://weibo.com/1727858283/Ncrax4uAC)

## 1.02. [ToolLLM：利用大型语言模型掌握 16000 多个真实世界的 API](https://github.com/OpenBMB/ToolBench)

该项目（ToolLLM）旨在构建开源、大规模、高质量的指令调优SFT数据，以方便构建具有通用工具使用能力的强大LLM。目标是让开源LLM能够掌握数千个不同的现实世界 API。项目通过收集高质量的指令调整数据集来实现这一目标。它是使用最新的ChatGPT（gpt-3.5-turbo-16k）自动构建的，并通过增强的函数调用能力进行了升级。项目提供数据集、相应的训练和评估脚本，以及在 ToolBench 上微调的强大模型 ToolLLaMA。

## 1.03. [基于MovieChat视频理解的问答，能够在24GB显卡上处理10K帧视频](https://github.com/rese1f/MovieChat)

## 1.04. [将google地图 3D模型 导入 Blender](https://twitter.com/xiaohuggg/status/1673192327551258624)

Imagiscope Tech 公司 开发插件，将全球任何地方的Google Earth的3D数据导入到Blender中。

用户只需设置位置，模型就会直接导入到场景中。

然后你就可以在Blender中轻松调整。

这对于需要在真实环境中进行建模的项目（如城市规划、GIS分析、电影和游戏设计等）非常有用。

## 1.05. [Meta开源了 AudioCraft：文本 -- 声音](https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio)

试用 MusicGen: huggingface.co/spaces/facebook/MusicGen

AudioCraft 框架，在对原始音频信号（而不是 MIDI 或钢琴卷轴）进行训练后，根据基于文本的用户输入生成高质量、逼真的音频和音乐。

AudioCraft 包含三个模型：MusicGen、AudioGen和EnCodec。MusicGen 使用 Meta 拥有且专门授权的音乐进行训练，根据基于文本的用户输入生成音乐，而 AudioGen 使用公共音效进行训练，根据基于文本的用户输入生成音频。今天，Meta发布了 EnCodec 解码器的改进版本，它可以用更少的音损生成更高质量的音乐；预先训练的 AudioGen 模型，可让你生成环境声音和声音效果，例如狗叫声、汽车喇叭声或木地板上的脚步声；以及所有 AudioCraft 模型权重和代码。这些模型可用于研究目的并加深人们对该技术的理解。

## 1.07. [PrettyPolly.app](https://www.prettypolly.app/)

学习外语时，最好有一个对话环境，可以练习口语。现在有一个 AI 应用，解决了这个问题。

它目前提供26种语言（包括中文、日文和韩文），你在网页上选择一种，就可以与 AI 进行口语练习了。

# 2. 项目 / 框架

## 2.01. [LLaMA2-Accessory：LLM 开发的开源工具包](https://github.com/Alpha-VLLM/LLaMA2-Accessory)

这个repo主要继承自LLaMA-Adapter

LLaMA2-Accessory是一个开源工具包，用于大型语言模型 (LLM)和多模式 LLM的预训练、微调和部署。

+ 💡支持更多数据集和任务
+ 🎯使用RefinedWeb和StarCoder进行预训练。
+ 📚使用Alpaca、ShareGPT、LIMA、UltraChat和MOSS进行单模态微调。
+ 🌈使用图像文本对（ LAION、COYO等）、交错图像文本数据（MMC4和OBELISC）和视觉指令数据（LLaVA、Shrika、Bard）进行多模态微调
+ 🔧API 控制LLM（GPT4Tools和Gorilla）。
+ ⚡高效优化和部署
+ 🚝通过零初始注意和偏差范数调整进行参数高效的微调。
+ 💻完全分片数据并行 ( FSDP )、Flash Attention 2和QLoRA。
+ 🏋️‍♀️支持更多视觉编码器和LLM
+ 👁‍🗨视觉编码器：CLIP、Q-Former和ImageBind。
+ 🧩LLM：LLaMA 和 LLaMA2。

## 2.02. [USearch：单文件向量搜索引擎](http://aicoco.net/s/4h)

支持多种度量方式和编程语言，提供高性能的向量搜索。特点包括支持自定义度量方式、高内存效率、硬件支持范围广泛、可从外部存储加载索引、支持语义搜索和连接等功能。与FAISS相比，USearch在设计原则和性能方面有一些区别


# 3. 模型

## 3.01. [把LLaMA-2的上下文扩展到32K](https://together.ai/blog/llama-2-7b-32k)

`Together.ai`发布了LLaMA-2-7B-32K模型。这个模型在LLaMA-2的基础上把上下文扩展到了32K。

## 3.02. [阿里: Qwen-7B 通义千问 开源版](https://github.com/QwenLM/Qwen-7B)

Qwen-7B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。

预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。

同时，在Qwen-7B的基础上，使用对齐机制打造了基于大语言模型的AI助手Qwen-7B-Chat。

## 3.03. [中文LLaMA-2 & Alpaca-2 LLM](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)

本项目基于Meta发布的可商用大模型Llama-2开发，是中文LLaMA&Alpaca大模型的第二期项目，开源了中文LLaMA-2基座模型和Alpaca-2指令精调大模型。

这些模型在原版Llama-2的基础上扩充并优化了中文词表，使用了大规模中文数据进行增量预训练，进一步提升了中文基础语义和指令理解能力，相比一代相关模型获得了显著性能提升。

相关模型支持4K上下文并可通过NTK方法最高扩展至18K+。

# 4. 技巧 / 教程

## 4.01. [《深度学习需要的`矩阵微积分`》](https://explained.ai/matrix-calculus)

## 4.02. [《llama2.c手把手代码解析》](https://github.com/RahulSChand/llama2.c-for-dummies)

## 4.03. [《图解 transformer》](https://jalammar.github.io/illustrated-transformer/)

## 4.04. [《可视化解释Stable Diffusion的工作原理》](https://github.com/poloclub/diffusion-explainer)
## 4.05. [《结构化 Prompt》](https://github.com/yzfly/LangGPT/blob/main/Docs/HowToWritestructuredPrompts.md)

## 4.06. [《LLM简明概述》：解释了大型语言模型(LLM)的工作原理](https://www.understandingai.org/p/large-language-models-explained-with)

首先介绍了词向量的概念，以及它们如何将词汇表示成向量空间中的点，详细介绍了transformer，这是构建LLMs的基本模块，解释了它们如何通过attention机制和前馈网络来理解文本并预测下一个词。

文章还指出LLM的开发方式导致人们目前对其内部工作机制并不完全理解，需要长期研究

# 5. 资讯 / 观点

