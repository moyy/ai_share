- [14. Azure OpenAI API](#14-azure-openai-api)
- [13. ChatDB: 利用 Langhain 和 Sql 整合 LLM](#13-chatdb-利用-langhain-和-sql-整合-llm)
- [12. 如何利用`OpenAI Function Calling` 解析递归机构](#12-如何利用openai-function-calling-解析递归机构)
- [11. replicate 提供 Stable Diffuse API](#11-replicate-提供-stable-diffuse-api)
- [10. Data-Driven Characters：用LangChain从现有语料生成特定角色聊天机器人](#10-data-driven-characters用langchain从现有语料生成特定角色聊天机器人)
- [09. FableForge：用单条提示生成整本图画书](#09-fableforge用单条提示生成整本图画书)
- [08. MultiPDF Chat App](#08-multipdf-chat-app)
- [07. 结合符号性记忆，清华等提出ChatDB，提升大模型的复杂推理能力](#07-结合符号性记忆清华等提出chatdb提升大模型的复杂推理能力)
- [06. WizardCoder: 编程任务仅次于GPT](#06-wizardcoder-编程任务仅次于gpt)
- [05. 斯坦福发布的LLM排行榜](#05-斯坦福发布的llm排行榜)
- [04. 开源软件 开发/管理 的 技能模型](#04-开源软件-开发管理-的-技能模型)
- [03. 普林斯顿：`Infinigen` 程序生成虚拟场景](#03-普林斯顿infinigen-程序生成虚拟场景)
- [02. Google发布 AI试衣模型 TryOnDiffusion](#02-google发布-ai试衣模型-tryondiffusion)
- [01. Vercel AI SDK: 前端版的`LangChain`](#01-vercel-ai-sdk-前端版的langchain)

# 14. [Azure OpenAI API](https://51.ruyo.net/18402.html)

需要：企业邮箱，企业官网；

+ （截至 2023.06）可能是国内唯一没有风控的OpenAI API 付费渠道
+ 企业邮箱：最快的是使用 腾讯 的 企业邮箱； 如果考虑到使用 海外接口 的 安全问题，可以使用 `aws`
+ [点这里](https://docs.aws.amazon.com/zh_cn/workmail/latest/adminguide/howto-start.html)：申请 `aws`账号；在`aws`买域名；按流程注册邮箱

可以直接使用OpenAI的模型（如ChatGPT和GPT-4）来处理你的数据。

Azure OpenAI 服务可以连接到任何数据源，无论数据存储在本地还是云端。此外，Azure OpenAI服务支持从多个数据源获取数据。

+ Azure认知搜索索引：您可以将数据连接到Azure认知搜索索引，从而实现与OpenAI模型的无缝集成。
+ Azure Blob 存储容器
+ 包括 txt, md, html, Word, ppt, pdf 等

Azure OpenAI服务提供了一个聊天沙盒环境，这是一个无代码环境，

用户可以在其中实验、迭代，并根据自己的提示生成完成的代码。

用户还可以选择直接从Azure AI工作室部署一个Web应用，创建一个可供组织访问的对话AI平台。

# 13. [ChatDB: 利用 Langhain 和 Sql 整合 LLM](https://www.jiqizhixin.com/articles/2023-06-20-8)

说白了，类似 Langchain 的一种Agent 的 使用模式；数据库表要根据场景自己设计；

+ 论文地址：https://arxiv.org/abs/2306.03901
+ 项目主页：https://chatdatabase.github.io
+ 项目代码：https://github.com/huchenxucs/ChatDB

近期，清华大学和北京智源人工智能研究院的研究者们提出了一种新型的符号性（symbolic）记忆模块。他们从现代计算机架构中汲取灵感，利用符号性记忆模块来增强大型语言模型。这种符号性记忆模块可以利用符号性的操作，精确的控制记忆模块中的信息。这样的符号性记忆框架由一个大语言模型（如 ChatGPT）和一个数据库组成，称为 ChatDB。

其中大语言模型负责控制对记忆模块的读写操作。在 ChatDB 中，大语言模型通过生成 SQL 指令来操纵数据库，从而实现对记忆模块中历史信息精确的增删改查，并在需要时为大语言模型提供信息，以帮助其回应用户的输入。这项研究可以让大语言模型胜任需要对历史信息进行长期且精确的记录、处理和分析的场景，例如各种管理和分析系统，以后甚至有望替代管理者，直接让大语言模型根据精确的历史数据做分析和决策。

# 12. [如何利用`OpenAI Function Calling` 解析递归机构](https://weibo.com/1727858283/4914861421363777)

`OpenAI`的`Function Calling`的 parameters 说明是基于`JSON schema`规范的

`JSON Schema`里面有一个特殊的关键字叫`$ref`

``` JSON

"children": {
  "type": "array",
  "description": "The tree nodes",
  "items": { "$ref": "#" }
}
```

# 11. [replicate 提供 Stable Diffuse API](https://replicate.com/)

[对比 Stability.ai 的 API 的 差异](https://www.similarweb.com/website/replicate.com/vs/stability.ai/#traffic)

注：不同的模型需要在不同的硬件运行，要查看demo和文档

三选一，具体看模型

+ `CPU`: $0.0002/秒；0.012/分
+ `NV T4`: $0.00055/秒; $0.033/分
+ `A100` 40GB: $0.0023/秒; $0.138/分

例子: 下面模型要在 `A100` 跑，9秒内算完，[mj-v4 类似 模型](https://replicate.com/tstramer/midjourney-diffusion)

# 10. [Data-Driven Characters：用LangChain从现有语料生成特定角色聊天机器人](https://github.com/mbchang/data-driven-characters)

Data-Driven Characters：用LangChain从现有语料生成特定角色聊天机器人

# 09. [FableForge：用单条提示生成整本图画书](https://github.com/e-johnstonn/FableForge)

`FableForge`：用单条提示生成整本图画书，基于`OpenAI`的function calling 和 `Replicate` 的 Stable Diffusion API

# 08. [MultiPDF Chat App](https://github.com/alejandro-ao/ask-multiple-pdfs)

MultiPDF Chat App：与多个PDF文档进行聊天，用自然语言提问，根据文档内容提供相关回答

# 07. [结合符号性记忆，清华等提出ChatDB，提升大模型的复杂推理能力](https://www.jiqizhixin.com/articles/2023-06-20-8)

+ 论文 https://arxiv.org/abs/2306.03901
+ 代码 https://github.com/huchenxucs/ChatDB

近期，清华大学和北京智源人工智能研究院的研究者们提出了一种新型的符号性（symbolic）记忆模块。他们从现代计算机架构中汲取灵感，利用符号性记忆模块来增强大型语言模型。这种符号性记忆模块可以利用符号性的操作，精确的控制记忆模块中的信息。这样的符号性记忆框架由一个大语言模型（如 ChatGPT）和一个数据库组成，称为 ChatDB。其中大语言模型负责控制对记忆模块的读写操作。在 ChatDB 中，大语言模型通过生成 SQL 指令来操纵数据库，从而实现对记忆模块中历史信息精确的增删改查，并在需要时为大语言模型提供信息，以帮助其回应用户的输入。这项研究可以让大语言模型胜任需要对历史信息进行长期且精确的记录、处理和分析的场景，例如各种管理和分析系统，以后甚至有望替代管理者，直接让大语言模型根据精确的历史数据做分析和决策。

# 06. [WizardCoder: 编程任务仅次于GPT](https://www.jiqizhixin.com/articles/2023-06-20-5)

![](../../images/20230620193724.png)

# 05. [斯坦福发布的LLM排行榜](https://tatsu-lab.github.io/alpaca_eval)

前十名：

|                      |        |
| -------------------- | ------ |
| GPT-4                | 95.28% |
| Claude               | 88.39% |
| ChatGPT              | 86.09% |
| WizardLM 13B         | 75.31% |
| Guanaco 65B          | 71.80% |
| Vicuna 13B           | 70.43% |
| LLaMA 33B OASST RLHF | 66.52% |
| Guanaco 33B          | 65.96% |
| Nous Hermes 13B      | 65.47% |
| Vicuna 7B            | 64.41% |

# 04. [开源软件 开发/管理 的 技能模型](https://arxiv.org/abs/2209.02222)

该模型包括 9个类别 的 45个技能：技术技能、工作风格、问题解决、贡献类型、项目特定技能、人际技能、外部关系、管理和特征。研究发现发现开源软件贡献者积极主动地提升技能，并认为与他人分享技能具有许多好处。同时该论文利用这一分析结果得出了一系列设计启示和最佳实践，供那些将技能纳入开源软件工具和平台（如GitHub）的人参考

# 03. [普林斯顿：`Infinigen` 程序生成虚拟场景](https://github.com/princeton-vl/infinigen)

普林斯顿刚开源了一个（开源免费的）元宇宙创世神器！`Infinigen`，用程序化的方式一键生成超逼真/多样化/UE5级别的虚拟场景！

感觉一下子解决了ACG场景生成 / 虚拟场景标注数据集生成两大问题，但是最大遗憾是目前所有场景几乎是随机生成的，如果将随机生成的代码和对应的场景之间加上人工对于这些场景的文字描述，构建一个“文字描述—虚拟实感场景模型—程序化代码+参数”的训练集，然后train一个 text 2 scene的AI，以后直接文字描述生成完备的三维拟真场景，这个未来简直不敢想象！

+ 程序化：Infinigen 不是有限的 3D 资产或合成图像集合，而是一个可以生成无限多不同形状、纹理、材质和场景组合的生成器。所以理论上可以生成无限多无限丰富的场景。
+ 完备性：Infinigen 提供了涵盖自然世界中各种物体和场景的广泛内容，包括植物、动物、地形以及火、云、雨和雪等自然现象。
+ 真实几何mesh：与视频游戏资产中通常使用纹理贴图来伪造几何细节（如表面看起来崎岖但实际上是平坦）不同，Infinigen 中所有几何mesh细节都是真实的。
+ 可转换构建虚拟数据集：由于最终数据的完备性，生成的场景很容易转换为法线、深度、目标检测、实例分割等多种配对数据集。
+ 自由且开源：Infinigen 基于 Blender构建。Infinigen 的代码在 GPL 许可下免费发布。粗看论文，好像是先生成几何节点，再从几何节点转为python？

# [02. Google发布 AI试衣模型 TryOnDiffusion](https://tryondiffusion.github.io/)

Google发布 AI 试衣模型 TryOnDiffusion，一张全身照和衣服照片就可以生成穿上衣服的照片

# [01. Vercel AI SDK: 前端版的`LangChain`](https://github.com/vercel-labs/ai)

Vercel发布了Vercel AI SDK，简直就是前端版的`LangChain`，支持多种LLM，支持Stream，提供了一个名字为“ai”的npm包，你运行 npm install ai 就可以加到你的前端项目。

现已集成 OpenAI、Hugging Face、LangChain 等知名 AI 开发工具。未来 AI 应用的开发效率将越来越快，成本越来越低。

目前已支持 React/Next.js、Svelte/SvelteKit，下一步将支持 Nuxt/Vue。